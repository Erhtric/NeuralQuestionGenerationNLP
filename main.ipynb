{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hlpy-ayWoEHa",
        "r7qxjGzKJM2w",
        "kx2f7Nn_4en9",
        "dtM9nOQrf3jq",
        "qyRA2RxZNsx4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erhtric/NeuralQuestionGenerationNLP/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the main file: its purpouse is to collect all the code coming from the coding pipeline."
      ],
      "metadata": {
        "id": "8OU-wpGL18xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htbwd0W_Y9IC",
        "outputId": "812371a7-e351-4584-820a-763f26af89ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "import re\n",
        "import os\n",
        "import typing\n",
        "from typing import Any, Tuple, List, NamedTuple\n",
        "import spacy\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "from gensim.models import KeyedVectors\n",
        "import seaborn as sns\n",
        "from itertools import chain\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from keras.layers import (\n",
        "    Layer, \n",
        "    Embedding, \n",
        "    LSTM, \n",
        "    Dense, \n",
        "    Bidirectional, \n",
        "    Input, \n",
        "    AdditiveAttention)\n",
        "\n",
        "import nltk\n",
        "from nltk import punkt, pos_tag, ne_chunk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLvONYDvKAHz",
        "outputId": "4cdaf18c-c79e-446e-c54f-1fbf4b5b1fcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CIZdy1hp14x8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbade8de-138d-4ec9-a304-4e17ac15921e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commands to prepare the folder to accomodate data."
      ],
      "metadata": {
        "id": "UqKVWPel_ybt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP/Project/Testing folder/Eric\n",
        "%pwd\n",
        "%mkdir data\n",
        "%mkdir training_checkpoints\n",
        "\n",
        "# disable chained assignments to avoid annoying warning\n",
        "pd.options.mode.chained_assignment = None "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKVGy7JPJCoi",
        "outputId": "6433ebb4-88bd-4599-c47b-5fc77f4435e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1cVw6eUwM-dRL9BhqtXULyOqeXDrYkwmH/NLP/Project/Testing folder/Eric\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘training_checkpoints’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print({tf.__version__})"
      ],
      "metadata": {
        "id": "-ePFW3UcrVtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595e60c5-6b9c-4672-abfa-8beb593e1265"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2.8.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is for the `configuration.json` file: "
      ],
      "metadata": {
        "id": "2hyzKyj_-GjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "units = 600\n",
        "\n",
        "dataset_config = {\n",
        "    # 'num_examples': 18896,\n",
        "    'num_examples': 9000,\n",
        "    'num_words': None,\n",
        "    'buffer_size': 32000,\n",
        "    'batch_size': batch_size,\n",
        "    'random_seed': 13,\n",
        "}\n",
        "\n",
        "encoder_config = {\n",
        "    'vocab_size': None,\n",
        "    'embedding_dimension': 300,\n",
        "    'units': units,\n",
        "    'batch_size': batch_size,\n",
        "    'max_length_context': None\n",
        "}\n",
        "\n",
        "decoder_config = {\n",
        "    'vocab_size': None,\n",
        "    'embedding_dimension': 300,\n",
        "    'units': units,\n",
        "    'batch_size': batch_size,\n",
        "    'max_length_question': None,\n",
        "    'max_length_context': None\n",
        "}\n",
        "\n",
        "trainer_config = {\n",
        "    'epochs': 3,\n",
        "    'optimizer': tf.optimizers.Adam(learning_rate=1e-3),\n",
        "    'loss': tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "}\n",
        "\n",
        "path = {\n",
        "    'training_json_path': \"./data/training_set.json\",\n",
        "    'save_pkl_path': \"./data/squadv2.pkl\"\n",
        "}"
      ],
      "metadata": {
        "id": "5bS3uLkE-Mvf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data handling and Pre-processing\n",
        "\n",
        "\n",
        "Things to do:\n",
        "1. Add to each sentence $x$ a start of sequence `<SOS>` tag and end of sequence `<EOS>` tag,\n",
        "2. Clean the sentences by removing special chars,\n",
        "3. Perform other preprocessing steps,\n",
        "4. Create a **vocabulary** with a word-to-index and index-to-word mappings by using a **tokenizer**, \n",
        "5. Extract the sentences that contain an answer and use them as input features, whereas the question will be our target\n",
        "6. Pad each context to maximum length.\n",
        "\n",
        "The resulting data that will be used hereinafter will be of type `tf.data.Dataset`. "
      ],
      "metadata": {
        "id": "sFBKCIE3Jxf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(NamedTuple):\n",
        "  \"\"\"\n",
        "  This class represent a a 3-way split processed dataset. \n",
        "  \"\"\"\n",
        "  # Reference :- https://github.com/topper-123/Articles/blob/master/New-interesting-data-types-in-Python3.rst\n",
        "  train: tf.data.Dataset\n",
        "  val: tf.data.Dataset\n",
        "  test: tf.data.Dataset\n",
        "\n",
        "class SQuAD:\n",
        "  def __init__(self):\n",
        "    self.random_seed = None\n",
        "    self.squad_df = None\n",
        "    self.preproc_squad_df = None\n",
        "    self.tokenizer = None\n",
        "    self.buffer_size = 0\n",
        "    self.batch_size = 0\n",
        "\n",
        "  def __call__(self,\n",
        "           num_examples, \n",
        "           buffer_size, \n",
        "           batch_size, \n",
        "           random_seed,\n",
        "           training_json_path,\n",
        "           save_pkl_path,\n",
        "           num_words=None,\n",
        "           tokenized=True,\n",
        "           pos_ner_tag=True,\n",
        "           tensor_type=True):\n",
        "    \"\"\"The call() method loads the SQuAD dataset, preprocess it and optionally it returns \n",
        "    it tokenized. Moreover it also perform a 3-way split.\n",
        "\n",
        "    Args:\n",
        "        num_examples (int): number of examples to be taken from the original SQuAD dataset\n",
        "        num_words (int): the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept. \n",
        "        buffer_size (int): buffer size for the shuffling operation\n",
        "        batch_size (int): size of the batches\n",
        "        tokenized (boolean): specifies if the context and question data should be both tokenized\n",
        "        pos_ner_tag (boolean):\n",
        "        tensro_type (boolean): \n",
        "\n",
        "    Returns (depending on the input parameters):\n",
        "        pd.DataFrame: training dataset\n",
        "        pd.DataFrame: validation dataset\n",
        "        pd.DataFrame: testing dataset\n",
        "          OR\n",
        "        NamedTuple: dataset, (dict, dict, dict)\n",
        "    \"\"\"\n",
        "    self.random_seed = random_seed\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.training_json_path = training_json_path\n",
        "    self.save_pkl_path = save_pkl_path\n",
        "    self.pos_ner_tag = pos_ner_tag\n",
        "\n",
        "    # Load dataset from file\n",
        "    self.load_dataset(num_examples)\n",
        "    # Extract answer\n",
        "    self.extract_answer()\n",
        "    # Preprocess context and question\n",
        "    self.preprocess()\n",
        "    \n",
        "    # Perform splitting\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = self.split_train_val(self.preproc_squad_df)\n",
        "    \n",
        "    if self.pos_ner_tag: \n",
        "      pass\n",
        "\n",
        "    # Initialize Tokenizer\n",
        "    self.tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', \n",
        "                                                           oov_token='<unk>',\n",
        "                                                           num_words=num_words)\n",
        "\n",
        "    if tokenized:\n",
        "      X_train_tokenized, _ = self.__tokenize_context(X_train)\n",
        "      y_train_tokenized, word_to_index_train = self.__tokenize_question(y_train)\n",
        "\n",
        "      X_val_tokenized, _ = self.__tokenize_context(X_val)\n",
        "      y_val_tokenized, word_to_index_val = self.__tokenize_question(y_val)\n",
        "\n",
        "      X_test_tokenized, _ = self.__tokenize_context(X_test)\n",
        "      y_test_tokenized, word_to_index_test = self.__tokenize_question(y_test)\n",
        "      if tensor_type:\n",
        "        # Returns tf.Data.Dataset objects (tokenized)\n",
        "        train_dataset = self.to_tensor(X_train_tokenized, y_train_tokenized)\n",
        "        val_dataset = self.to_tensor(X_val_tokenized, y_val_tokenized)\n",
        "        test_dataset = self.to_tensor(X_test_tokenized, y_test_tokenized)\n",
        "\n",
        "        dataset = Dataset(\n",
        "            train=train_dataset, \n",
        "            val=val_dataset,\n",
        "            test=test_dataset)\n",
        "\n",
        "        return dataset, (word_to_index_train, word_to_index_val, word_to_index_test)\n",
        "      else:\n",
        "        # Returns pd.DataFrame objects (tokenized)\n",
        "        return X_train_tokenized, y_train_tokenized, X_val_tokenized, y_val_tokenized, X_test_tokenized, y_test_tokenized\n",
        "    else:\n",
        "      return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "  def load_dataset(self, num_examples):\n",
        "    \"\"\"\n",
        "    Extract the dataset from the json file. Already grouped by title.\n",
        "\n",
        "    :param path: [Optional] specifies the local path where the training_set.json file is located\n",
        "\n",
        "    :return\n",
        "        - the extracted dataset in a dataframe format\n",
        "    \"\"\"\n",
        "    if os.path.exists(self.save_pkl_path):\n",
        "      print('File already exists! Loading from .pkl...\\n')\n",
        "      self.squad_df = pd.read_pickle(self.save_pkl_path)\n",
        "      self.squad_df = self.squad_df[:num_examples]\n",
        "    else:\n",
        "      print('Loading from .json...\\n')\n",
        "      with open(self.training_json_path) as f:\n",
        "          data = json.load(f)\n",
        "\n",
        "      df_array = []\n",
        "      for current_subject in data['data']:\n",
        "          title = current_subject['title']\n",
        "\n",
        "          for current_context in current_subject['paragraphs']:\n",
        "              context = current_context['context']\n",
        "\n",
        "              for current_question in current_context['qas']:\n",
        "                  question = current_question['question']\n",
        "                  id = current_question['id']\n",
        "\n",
        "              for answer_text in current_question['answers']:\n",
        "                    answer = answer_text['text']\n",
        "                    answer_start = answer_text['answer_start']\n",
        "                    record = { \"id\": id,\n",
        "                                \"title\": title,\n",
        "                                \"context\": context,\n",
        "                                \"question\": question,\n",
        "                                \"answer_start\": answer_start,\n",
        "                                \"answer\": answer\n",
        "                                }\n",
        "\n",
        "              df_array.append(record)\n",
        "      \n",
        "      # Save file\n",
        "      pd.to_pickle(pd.DataFrame(df_array), self.save_pkl_path)\n",
        "      self.squad_df = pd.DataFrame(df_array)[:num_examples]\n",
        "\n",
        "  def preprocess(self):\n",
        "    df = self.squad_df.copy()\n",
        "\n",
        "    # Pre-processing context\n",
        "    context = list(df.context)\n",
        "    preproc_context = []\n",
        "\n",
        "    for c in context:\n",
        "      c = self.__preprocess_sentence(c, question=False)\n",
        "      preproc_context.append(c)\n",
        "    \n",
        "    df.context = preproc_context\n",
        "\n",
        "    # Pre-processing questions\n",
        "    question = list(df.question)\n",
        "    preproc_question = []\n",
        "\n",
        "    for q in question:\n",
        "      q = self.__preprocess_sentence(q, question=True)\n",
        "      preproc_question.append(q)\n",
        "    \n",
        "    df.question = preproc_question\n",
        "\n",
        "    # Remove features that are not useful\n",
        "    df = df.drop(['id'], axis=1)\n",
        "    self.preproc_squad_df = df\n",
        "\n",
        "  def __preprocess_sentence(self, sen, question):\n",
        "    # Creating a space between a word and the punctuation following it\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    sen = re.sub(r\"([?.!,¿])\", r\" \\1 \", sen)\n",
        "    sen = re.sub(r'[\" \"]+', \" \", sen)\n",
        "\n",
        "    # Replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sen = re.sub(r\"[^a-zA-Z0-9?.!,¿]+\", \" \", sen)\n",
        "\n",
        "    sen = sen.strip()\n",
        "\n",
        "    # Adding a start and an end token to the sentence so that the model know when to \n",
        "    # start and stop predicting.\n",
        "    # if not question: sen = '<SOS> ' + sen + ' <EOS>'\n",
        "    sen = '<SOS> ' + sen + ' <EOS>'\n",
        "    return sen\n",
        "\n",
        "  def __answer_start_end(self, df):\n",
        "    \"\"\"\n",
        "    Creates a list of starting indexes and ending indexes for the answers.\n",
        "\n",
        "    :param df: the target Dataframe\n",
        "\n",
        "    :return: a dataframe containing the start and the end indexes foreach answer (ending index is excluded).\n",
        "\n",
        "    \"\"\"\n",
        "    start_idx = df.answer_start\n",
        "    end_idx = [start + len(list(answer)) for start, answer in zip(list(start_idx), list(df.answer))]\n",
        "    return pd.DataFrame(list(zip(start_idx, end_idx)), columns=['start', 'end'])\n",
        "\n",
        "  def split_train_val(self, df, train_size=0.8):\n",
        "    \"\"\"\n",
        "    This method splits the dataframe in training and test sets, or eventually, in training, validation and test sets.\n",
        "\n",
        "    Args\n",
        "        :param df: the target Dataframe\n",
        "        :param random_seed: random seed used in the splits\n",
        "        :param train_size: represents the absolute number of train samples\n",
        "        :param val: boolean for choosing between a 3-way split or 2-way one.\n",
        "\n",
        "    Returns:\n",
        "        - Data and labels for training, validation and test sets if val is True \n",
        "        - Data and labels for training and test sets if val is False \n",
        "\n",
        "    \"\"\"\n",
        "    # Maybe we have also to return the index for the starting answer\n",
        "    X = df.drop(['answer_start', 'question', 'answer'], axis=1).copy()\n",
        "    idx = self.__answer_start_end(df)\n",
        "    X['start'] = idx['start']\n",
        "    X['end'] = idx['end']\n",
        "    y = df['question']\n",
        "\n",
        "    # In the first step we will split the data in training and remaining dataset\n",
        "    splitter = GroupShuffleSplit(train_size=train_size, n_splits=2, random_state=self.random_seed)\n",
        "    split = splitter.split(X, groups=X['title'])\n",
        "    train_idx, rem_idx = next(split)\n",
        "\n",
        "    X_train = X.iloc[train_idx]\n",
        "    y_train = y.iloc[train_idx]\n",
        "    X_rem = X.iloc[rem_idx]\n",
        "    y_rem = y.iloc[rem_idx]\n",
        "\n",
        "\n",
        "    # Val and test test accounts for 10% of the total data. Both 5%.\n",
        "    splitter = GroupShuffleSplit(train_size=train_size, n_splits=2, random_state=self.random_seed)\n",
        "    split = splitter.split(X_rem, groups=X_rem['title'])\n",
        "    val_idx, test_idx = next(split)\n",
        "\n",
        "    X_val = X_rem.iloc[val_idx]\n",
        "    y_val = y_rem.iloc[val_idx]\n",
        "\n",
        "    X_test = X_rem.iloc[test_idx]\n",
        "    y_test = y_rem.iloc[test_idx]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "  def __tokenize_context(self, X):\n",
        "    context = X.context\n",
        "    self.tokenizer.fit_on_texts(context)\n",
        "    context_tf = self.tokenizer.texts_to_sequences(context)\n",
        "\n",
        "    # context_lengths = [len(seq) for seq in context_tf]\n",
        "    # sns.boxplot(context_lengths)\n",
        "\n",
        "    context_tf_pad = tf.keras.preprocessing.sequence.pad_sequences(context_tf, padding='post')\n",
        "\n",
        "    for i, _ in enumerate(context):\n",
        "      X['context'].iloc[i] = context_tf_pad[i]\n",
        "\n",
        "    return X, self.tokenizer.word_index\n",
        "\n",
        "  def __tokenize_question(self, y):\n",
        "    question = y\n",
        "    self.tokenizer.fit_on_texts(question)\n",
        "    question_tf = self.tokenizer.texts_to_sequences(question)\n",
        "\n",
        "    # question_lengths = [len(seq) for seq in question_tf]\n",
        "    # sns.boxplot(question_lengths)\n",
        "    \n",
        "    # See also tf.data.Dataset.padding_batch\n",
        "    question_tf_pad = tf.keras.preprocessing.sequence.pad_sequences(question_tf, padding='post')\n",
        "\n",
        "    for i, _ in enumerate(question):\n",
        "      y.iloc[i] = question_tf_pad[i]\n",
        "\n",
        "    # Add the padding\n",
        "    self.tokenizer.word_index['<pad>'] = 0\n",
        "    self.tokenizer.index_word[0] = '<pad>'\n",
        "\n",
        "    return y, self.tokenizer.word_index\n",
        "\n",
        "  def extract_answer(self):\n",
        "    df = self.squad_df.copy()\n",
        "    start_end = self.__answer_start_end(df)\n",
        "    context = list(df.context)\n",
        "    \n",
        "    selected_sentences = []\n",
        "    for i, par in enumerate(context):\n",
        "      sentences = sent_tokenize(par)\n",
        "      start = start_end.iloc[i].start\n",
        "      end = start_end.iloc[i].end      \n",
        "      right_sentence = \"\"\n",
        "      context_characters = 0\n",
        "\n",
        "      for j, sen in enumerate(sentences):\n",
        "        sen += ' '\n",
        "        context_characters += len(sen)\n",
        "        # If the answer is completely in the current sentence\n",
        "        if(start < context_characters and end <= context_characters):\n",
        "          right_sentence = sen\n",
        "          selected_sentences.append(right_sentence)\n",
        "          break\n",
        "        # the answer is in both the current and the next sentence\n",
        "        if(start < context_characters and end > context_characters):\n",
        "          right_sentence = sen + sentences[j+1]\n",
        "          selected_sentences.append(right_sentence)\n",
        "          break \n",
        "\n",
        "    self.squad_df.context = selected_sentences\n",
        "\n",
        "  def to_tensor(self, X, y):\n",
        "    X = X.context.copy()\n",
        "    y = y.copy()\n",
        "\n",
        "    # Reference:- https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (tf.cast(list(X), tf.int64), \n",
        "         tf.cast(list(y), tf.int64)))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "XyCKxqwRZelj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By calling the `SQuAD` constructor we create a dataset handling object which will be useful for future operations."
      ],
      "metadata": {
        "id": "iTXVdOGcZSCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_creator = SQuAD()"
      ],
      "metadata": {
        "id": "RfCYdZofJ866"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Preprocessed untokenized split"
      ],
      "metadata": {
        "id": "ZgeJckqZIufT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator.call(num_examples=dataset_creator.og_n_samples+1,\n",
        "#                                                                       num_words=None,\n",
        "#                                                                       BUFFER_SIZE=32000,\n",
        "#                                                                       BATCH_SIZE=64,\n",
        "#                                                                       random_seed=RANDOM_SEED,\n",
        "#                                                                       tokenized=False)\n",
        "\n",
        "# print(f'Set target: {X_train.columns.values}')\n",
        "\n",
        "# print(f'Train set samples: {X_train.shape[0]}')\n",
        "# print(f'Validation set samples: {X_val.shape[0]}')\n",
        "# print(f'Test set samples: {X_test.shape[0]}')\n",
        "\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator(**dataset_config, **path, tokenized=False)"
      ],
      "metadata": {
        "id": "TJFUuu2Y5hc-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Tokenized split"
      ],
      "metadata": {
        "id": "dndR7_CNI1jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Tensor Ready\n",
        "\n",
        "This is the data produced that we are most interested in. As we can see we will have:\n",
        "- a data structure `dataset` containing the training, validation and test set;\n",
        "- a tuple containing the word-to-token mappings for the training, validation and test set respectively."
      ],
      "metadata": {
        "id": "MvU7n1LboA6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "%%time\n",
        "dataset, word_to_idx = dataset_creator(**dataset_config, **path, tokenized=True)\n",
        "\n",
        "max_length_context = dataset.train.element_spec[0].shape[1]\n",
        "max_length_question = dataset.train.element_spec[1].shape[1]\n",
        "\n",
        "print(f'Sentences max lenght: {max_length_context}')\n",
        "print(f'Questions max lenght: {max_length_question}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax999y7aI75Y",
        "outputId": "edf6d10a-f660-4eb4-faca-2669cf1fc3b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists! Loading from .pkl...\n",
            "\n",
            "Sentences max lenght: 389\n",
            "Questions max lenght: 40\n",
            "CPU times: user 15.1 s, sys: 771 ms, total: 15.9 s\n",
            "Wall time: 20.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing such `NamedTuple` data structure is pretty simple, namely in a:\n",
        "1. tuple-way by accessing it like a list, e.g. `train = dataset[0]`,\n",
        "2. object-way by calling the instance parameters, e.g. `train = dataset.train`."
      ],
      "metadata": {
        "id": "W7hARM_R2Kod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Standard"
      ],
      "metadata": {
        "id": "hlpy-ayWoEHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator.call(num_examples=dataset_creator.og_n_samples+1,\n",
        "#                      BUFFER_SIZE=32000,\n",
        "#                      BATCH_SIZE=64,\n",
        "#                      random_seed=RANDOM_SEED,\n",
        "#                      tokenized=True,\n",
        "#                      tensor_type=False)\n",
        "\n",
        "# print(f'\\nSet target: {X_train.columns.values}')\n",
        "\n",
        "# print(f'Train set samples: {X_train.shape[0]}')\n",
        "# print(f'Validation set samples: {X_val.shape[0]}')\n",
        "# print(f'Test set samples: {X_test.shape[0]}')"
      ],
      "metadata": {
        "id": "vJFBk-r8eIcj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Original SQuAD dataset"
      ],
      "metadata": {
        "id": "r7qxjGzKJM2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original dataset\n",
        "# squad_df = dataset_creator.squad_df\n",
        "# print(f'[Info] SQuAD target: {list(squad_df.columns.values)}')\n",
        "# print(f'[Info] Shape: {squad_df.shape}')"
      ],
      "metadata": {
        "id": "9qhTAc5NErOk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. GloVe and embedding matrix"
      ],
      "metadata": {
        "id": "kx2f7Nn_4en9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVe:\n",
        "  def __init__(self, embedding_dimension):\n",
        "    self.embedding_dimension = embedding_dimension\n",
        "\n",
        "    try:\n",
        "      self.embedding_model = KeyedVectors.load(f'./data/glove_model_{self.embedding_dimension}')\n",
        "    except FileNotFoundError:\n",
        "      print('[Warning] Model not found in local folder, please wait...')\n",
        "      self.embedding_model = self.load_glove()\n",
        "      self.embedding_model.save(f'./data/glove_model_{self.embedding_dimension}')  \n",
        "      print('Download finished. Model loaded!')\n",
        "\n",
        "  def load_glove(self):\n",
        "    \"\"\"\n",
        "    Loads a pre-trained GloVe embedding model via gensim library.\n",
        "\n",
        "    We have a matrix that associate words to a vector of a user-defined dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    download_path = \"glove-wiki-gigaword-{}\".format(self.embedding_dimension)\n",
        "\n",
        "    try:\n",
        "      emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "      print(\"Generic error when loading GloVe\")\n",
        "      print(\"Check embedding dimension\")\n",
        "      raise e\n",
        "\n",
        "    emb_model = gloader.load(download_path)\n",
        "    return emb_model\n",
        "\n",
        "  def build_embedding_matrix(self, word_to_idx, vocab_size: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the \n",
        "        dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, self.embedding_dimension), dtype=np.float32)\n",
        "    oov_count = 0\n",
        "    oov_words = []\n",
        "\n",
        "    # For each word which is not present in the vocabulary we assign a random vector, otherwise we take the GloVe embedding\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "      try:\n",
        "        embedding_vector = self.embedding_model[word]\n",
        "      except (KeyError, TypeError):\n",
        "        oov_count += 1\n",
        "        oov_words.append(word)\n",
        "        # embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "        embedding_vector = np.random.uniform(low=-0.05, \n",
        "                                             high=0.05, \n",
        "                                             size=self.embedding_dimension)\n",
        "\n",
        "      embedding_matrix[idx] = embedding_vector\n",
        "    \n",
        "    print(f'\\n[Debug] {oov_count} OOV words found!')\n",
        "    return embedding_matrix, oov_words"
      ],
      "metadata": {
        "id": "TRJ1NpSMqaJL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to initialize the handler with the desidered `embedding_dimension`. Then to build the embedding matrix with the pre-trained GloVe embeddings simply call the `build_embedding_matrix` method."
      ],
      "metadata": {
        "id": "gk-z8A5y3cpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize the handler for GloVe\n",
        "glove_handler = GloVe(encoder_config['embedding_dimension'])\n",
        "\n",
        "# We will create the matrix by using only the words present in the training and validation set\n",
        "embedding_matrix, oov_words = glove_handler.build_embedding_matrix(\n",
        "    word_to_idx[1], \n",
        "    len(word_to_idx[1])+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUmvdCWGavSR",
        "outputId": "ab09a7ec-48bd-440a-bf75-4716fba19d3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warning] Model not found in local folder, please wait...\n",
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n",
            "Download finished. Model loaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27511/27511 [00:00<00:00, 79611.85it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] 2034 OOV words found!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Definition"
      ],
      "metadata": {
        "id": "FF5Rtd4uqa_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_context_batch, example_question_batch = next(iter(dataset.train))"
      ],
      "metadata": {
        "id": "GjdRysIvPoLc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1StCU2NBnniP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Encoder\n",
        "We will use a bidirectional LSTM to encode the sentence,\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\overrightarrow{b_t} &= \\overrightarrow{\\text{LSTM}}(x_t, \\overrightarrow{b_{t-1}})\\\\\n",
        "\\overleftarrow{b_t} &= \\overleftarrow{\\text{LSTM}}(x_t, \\overleftarrow{b_{t+1}})\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "where $\\overrightarrow{b_t}$ is the hidden state at time step $t$ for the forward pass LSTM and $\\overleftarrow{b_t}$ for the backward pass."
      ],
      "metadata": {
        "id": "wjVfZgIIf1RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               vocab_size, \n",
        "               embedding_matrix,\n",
        "               embedding_dimension, \n",
        "               units, \n",
        "               batch_size, \n",
        "               max_length_context,\n",
        "               **kwargs):\n",
        "    super(Encoder, self).__init__(**kwargs)\n",
        "    self.batch_size = tf.constant(batch_size)\n",
        "    self.max_length_context = tf.constant(max_length_context)\n",
        "\n",
        "    # Layers\n",
        "    self.inputs = Input(shape=(self.max_length_context,), name='encoder_input')\n",
        "    \n",
        "    self.embedding = Embedding(input_dim=vocab_size+1,\n",
        "                               output_dim=embedding_dimension,\n",
        "                               input_length=self.max_length_context,\n",
        "                               embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                               trainable=False,\n",
        "                               mask_zero=False,\n",
        "                               name='encoder_embedding_layer')\n",
        "    \n",
        "    # The LSTM forward pass\n",
        "    self.forward_lstm_layer = LSTM(units//2,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform',\n",
        "                                  use_bias=True,\n",
        "                                  input_shape=(self.max_length_context, embedding_dimension),\n",
        "                                  name='encoder_flstm_layer')\n",
        "    \n",
        "    # The LSTM backward pass\n",
        "    self.backward_lstm_layer = LSTM(units//2,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  go_backwards=True,\n",
        "                                  recurrent_initializer='glorot_uniform',\n",
        "                                  use_bias=True,\n",
        "                                  input_shape=(self.max_length_context, embedding_dimension),\n",
        "                                  name='encoder_blstm_layer')\n",
        "    \n",
        "    # The Bidirectional wrapper\n",
        "    self.bidirectional_lstm = Bidirectional(self.forward_lstm_layer, \n",
        "                                            backward_layer=self.backward_lstm_layer, \n",
        "                                            name='encoder_bi_lstm',\n",
        "                                            merge_mode='concat')\n",
        "    \n",
        "  def call(self, inputs, state=None):\n",
        "    # shape = (batch_size, max_length_context)\n",
        "    x = self.embedding(inputs)\n",
        "\n",
        "    # encoder_outputs shape = (batch_size, max_length_context, embedding_dimension)\n",
        "    # forward_h shape = (batch_size, units//2)\n",
        "    # forward_c shape = (batch_size, units//2)\n",
        "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = self.bidirectional_lstm(x, initial_state=state)\n",
        "    \n",
        "    # concat shape = (batch_size, units) \n",
        "    h_concat = tf.concat([forward_h, backward_h], axis=1)\n",
        "    c_concat = tf.concat([forward_c, backward_c], axis=1)\n",
        "    return encoder_outputs, (h_concat, c_concat)\n",
        "\n",
        "  ##### VISUALIZATION METHODS #####\n",
        "  # Reference :- https://stackoverflow.com/questions/61427583/how-do-i-plot-a-keras-tensorflow-subclassing-api-model\n",
        "  def build_graph(self):\n",
        "    x = Input(shape=(self.max_length_context,), batch_size=self.batch_size)\n",
        "    return tf.keras.Model(inputs=x, outputs=self.call(x))\n",
        "  \n",
        "  def plot_model(self):\n",
        "    return tf.keras.utils.plot_model(\n",
        "        self.build_graph(), \n",
        "        to_file='encoder.png', dpi=96,              \n",
        "        show_shapes=True, show_layer_names=True,  \n",
        "        expand_nested=False                       \n",
        "    )"
      ],
      "metadata": {
        "id": "GK6Kd1XvqK22"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Test the encoder stack\n",
        "\n"
      ],
      "metadata": {
        "id": "fbjSxPGcFud_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_config['vocab_size'] = len(word_to_idx[1])\n",
        "encoder_config['max_length_context'] = dataset.train.element_spec[0].shape[1]\n",
        "\n",
        "encoder = Encoder(**encoder_config, embedding_matrix=embedding_matrix)\n",
        "encoder_outputs, encoder_state = encoder(inputs=example_context_batch)\n",
        "\n",
        "hidden_state, cell_state = encoder_state\n",
        "\n",
        "print(f'Decoder output shape: (batch_size, max_length_context, units): {encoder_outputs.shape}')\n",
        "print(f'Hidden state shape: (batch_size, units): {hidden_state.shape}')\n",
        "print(f'Cell state shape: (batch_size, units): {cell_state.shape}')"
      ],
      "metadata": {
        "id": "_ffteDMQyzmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41780633-7824-4773-dc3e-1be7c5c6f124"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, max_length_context, units): (64, 389, 600)\n",
            "Hidden state shape: (batch_size, units): (64, 600)\n",
            "Cell state shape: (batch_size, units): (64, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.build_graph().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng97TFpLRym2",
        "outputId": "67b9463a-c737-4ed0-8cfe-4d3eef3b8b24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(64, 389)]          0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding_layer (Embed  (64, 389, 300)      8253600     ['input_1[0][0]']                \n",
            " ding)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_bi_lstm (Bidirectional  [(64, 389, 600),    1442400     ['encoder_embedding_layer[0][0]']\n",
            " )                               (64, 300),                                                       \n",
            "                                 (64, 300),                                                       \n",
            "                                 (64, 300),                                                       \n",
            "                                 (64, 300)]                                                       \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (64, 600)            0           ['encoder_bi_lstm[0][1]',        \n",
            "                                                                  'encoder_bi_lstm[0][3]']        \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (64, 600)            0           ['encoder_bi_lstm[0][2]',        \n",
            "                                                                  'encoder_bi_lstm[0][4]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,696,000\n",
            "Trainable params: 1,442,400\n",
            "Non-trainable params: 8,253,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.plot_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "aaJFf-ELdIZo",
        "outputId": "8d224712-3dc8-4ec1-ebd8-308d88263228"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Decoder"
      ],
      "metadata": {
        "id": "dtM9nOQrf3jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Container classes\n",
        "# Reference :- https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "class DecoderInput(NamedTuple):\n",
        "  new_token: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "metadata": {
        "id": "73wq7CTiTQpX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  # Reference:- https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    self.W1 = Dense(units, use_bias=False, name='Wb1_attention_weights')\n",
        "    self.W2 = Dense(units, use_bias=False, name='Wb2_attention_weights')\n",
        "\n",
        "    self.attention = AdditiveAttention(use_scale=True)\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    \"\"\"\n",
        "    This layer takes 3 inputs:\n",
        "      - the query; this will be generated by the decoder, later,\n",
        "      - the value: the output of the encoder,\n",
        "      - the mask: to exclude the padding, i.e., context_batch != 0.\n",
        "    \"\"\"\n",
        "    #W1@ht\n",
        "    w1_query = self.W1(query)\n",
        "    #W2@hs\n",
        "    w2_key = self.W2(value)\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask = [query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    \n",
        "    return context_vector, attention_weights\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               vocab_size, \n",
        "               embedding_matrix, \n",
        "               embedding_dimension,\n",
        "               units, \n",
        "               batch_size, \n",
        "               max_length_context,\n",
        "               max_length_question,\n",
        "               **kwargs):\n",
        "    \n",
        "    super(Decoder, self).__init__(**kwargs)\n",
        "    self.batch_size = tf.constant(batch_size)\n",
        "    self.max_length_question = max_length_question\n",
        "    self.max_length_context = tf.constant(max_length_context)\n",
        "    self.embedding_dimension = tf.constant(embedding_dimension)\n",
        "    self.units = tf.constant(units)\n",
        "\n",
        "    # Layers definition\n",
        "    self.inputs = Input(shape=(None,), batch_size=self.batch_size)\n",
        "                        \n",
        "    # Embedding for the questions\n",
        "    self.embedding = Embedding(input_dim=vocab_size+1,\n",
        "                               output_dim=embedding_dimension,\n",
        "                               input_length=self.max_length_question,\n",
        "                               embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                               trainable=False,  #?\n",
        "                               mask_zero=False,\n",
        "                               name='decoder_embedding_layer')\n",
        "    \n",
        "    # The LSTM layer\n",
        "    self.lstm_layer = LSTM(units,\n",
        "                          return_sequences=True,\n",
        "                          return_state=True,\n",
        "                          recurrent_initializer='glorot_uniform',\n",
        "                          use_bias=True,\n",
        "                          input_shape=(self.max_length_question, embedding_dimension),\n",
        "                          name='decoder_lstm_layer')\n",
        "\n",
        "    # The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(units)\n",
        "\n",
        "    # Parameters to be learned\n",
        "    self.Wt = Dense(units, activation=tf.math.tanh, use_bias=False, name='decoder_Wt_weights')\n",
        "\n",
        "    # For the word probabilities\n",
        "    # self.Ws = Dense(self.dec_units, activation=tf.nn.softmax, use_bias=False)\n",
        "    self.Ws = Dense(vocab_size, activation=tf.nn.softmax, use_bias=False, name='decoder_Ws_weights')\n",
        "\n",
        "  def call(self, \n",
        "            inputs: DecoderInput, \n",
        "            state=None) -> Tuple[DecoderOutput, Tuple[tf.Tensor]]:\n",
        "\n",
        "    # Lookup the embeddings for the questions\n",
        "    x = self.embedding(inputs.new_token)\n",
        "    # embedded_tensor shape: (batch_size, 1, embedding_dimension)\n",
        "    if tf.shape(x).shape == 2: x = tf.expand_dims(x, axis=1)\n",
        "\n",
        "    # Process one step with the RNN\n",
        "    # LSTM expects inputs of shape: (batch_size, timestep, feature)\n",
        "    cell_output, hidden_dec_state, cell_dec_state = self.lstm_layer(x, initial_state=state)\n",
        "\n",
        "    # Use the LSTM cell output as the query for the attention over the encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=cell_output, \n",
        "        value=inputs.enc_output, \n",
        "        mask=inputs.mask)\n",
        "\n",
        "    # Join the context_vector and cell outpyt [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    cell_output_and_context_vector = tf.concat([cell_output, context_vector], axis=-1)\n",
        "\n",
        "    # at = tanh(Wt@[ht, ct])\n",
        "    attention_vector = self.Wt(cell_output_and_context_vector)\n",
        "\n",
        "    # logits = softmax(Ws@at)\n",
        "    logits = self.Ws(attention_vector)\n",
        "\n",
        "    return DecoderOutput(logits, attention_weights), (hidden_dec_state, cell_dec_state)"
      ],
      "metadata": {
        "id": "V_-Lef2CqUW2"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Test the decoder stack\n",
        "\n",
        "The decoder will take as input:\n",
        "1. `new_tokens`: the last token generated of shape `(batch_size, 1)`, namely the token obrained in the previous time step of the decoder (we will initialize the decoder with the `\"<sos>\"` token);\n",
        "2. `enc_output`: this is the representation produced by the `Encoder` of shape `(batch_size, max_length_context, enc_units)`;\n",
        "3. `mask`: this is the mask, that is a boolean tensor, indicating which tokens will be considered in the decoding of shape `(batch_size, max_length_context)`; \n",
        "4. `decoder_state`: the previous state of the decoder, namely the internal state of the decoder's LSTM (the paper suggests to input the hidden and cell state produced by the Bi-LSTM). The shape is `[(batch_size, enc_units), (batch_size, enc_units)]`.\n",
        "\n"
      ],
      "metadata": {
        "id": "IF5J42g1l-be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_config['vocab_size'] = len(word_to_idx[1])\n",
        "decoder_config['max_length_question'] = dataset.train.element_spec[1].shape[1]\n",
        "decoder_config['max_length_context'] = dataset.train.element_spec[0].shape[1]\n",
        "\n",
        "decoder = Decoder(**decoder_config, embedding_matrix=embedding_matrix)"
      ],
      "metadata": {
        "id": "kS0UBnMzTbie"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "start_tag_index = word_to_idx[2]['<sos>']\n",
        "first_token = tf.squeeze(tf.constant([[start_tag_index]] * decoder_config['batch_size']), axis=1)\n",
        "# first_token = tf.constant([[4]] * decoder_config['batch_size'])"
      ],
      "metadata": {
        "id": "KeMvqDnrTkf0"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result, decoder_state = decoder(\n",
        "    inputs = DecoderInput(first_token, \n",
        "                          encoder_outputs,\n",
        "                          mask=(example_context_batch != 0)),\n",
        "    state = encoder_state\n",
        ")\n",
        "\n",
        "hidden_dec_state, cell_dec_state = decoder_state\n",
        "\n",
        "print(f'Logits shape: (batch_size, t, output_vocab_size) {decoder_result.logits.shape}')\n",
        "print(f'Hidden state shape: (batch_size, dec_units) {hidden_dec_state.shape}')\n",
        "print(f'Cell state shape: (batch_size, dec_units) {cell_dec_state.shape}')"
      ],
      "metadata": {
        "id": "BF6PWsNYfmUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf4b185-c245-4bb0-b692-3bc94e232525"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (batch_size, t, output_vocab_size) (64, 1, 27511)\n",
            "Hidden state shape: (batch_size, dec_units) (64, 600)\n",
            "Cell state shape: (batch_size, dec_units) (64, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we cannot provide a detailed summary or a handy plot due to the fact that we pass to the decoder model a structured input which is not preferred by tensorflow."
      ],
      "metadata": {
        "id": "T9FZVz2QyLkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1AJWwcDacEj",
        "outputId": "f0a62376-b402-4e7a-b1e2-90d281ca677c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_embedding_layer (Em  multiple                 8253600   \n",
            " bedding)                                                        \n",
            "                                                                 \n",
            " decoder_lstm_layer (LSTM)   multiple                  2162400   \n",
            "                                                                 \n",
            " bahdanau_attention_9 (Bahda  multiple                 720600    \n",
            " nauAttention)                                                   \n",
            "                                                                 \n",
            " decoder_Wt_weights (Dense)  multiple                  720000    \n",
            "                                                                 \n",
            " decoder_Ws_weights (Dense)  multiple                  16506600  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,363,200\n",
            "Trainable params: 20,109,600\n",
            "Non-trainable params: 8,253,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on. This means that the decoder will produce a vector of probabilities associated to each vocabulary word. That is, a vector of logits $l_b \\in \\mathbb{R}^{\\mathcal{V}}$ for each element $b$ in the batch, namely indicating the next probable token for a given sentence. Since they are logits they should sum up to `1.0`, evenutally a number really close to it. "
      ],
      "metadata": {
        "id": "BBIQDE0Sl6k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result.logits[0, 0, :].numpy().sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO-C7ELdlv1u",
        "outputId": "98d2d45f-b0e0-4f77-c3cc-6f755c61d8f4"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we sample a token according to the logits computed by the decoder."
      ],
      "metadata": {
        "id": "xrN_dTRtGdQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_tokens = tf.random.categorical(\n",
        "    logits=decoder_result.logits[:, 0, :],\n",
        "    num_samples=1, \n",
        "    seed=dataset_config['random_seed'])\n",
        "vocab = np.array(list(word_to_idx[1].keys()))\n",
        "\n",
        "first_word = list(vocab[tf.squeeze(sampled_tokens, axis=-1).numpy()])\n",
        "first_word[:5]"
      ],
      "metadata": {
        "id": "kGGwivobvx_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d039b11a-685d-4516-b47d-9d2dab768ce3"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['potent', 'armistice', 'percentage', 'freehand', 'czechoslovak']"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IO1MeOs9Q_-L"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result, _ = decoder(\n",
        "    inputs = DecoderInput(sampled_tokens, \n",
        "                          encoder_outputs,\n",
        "                          mask=(example_context_batch != 0)),\n",
        "    state = decoder_state\n",
        ")\n",
        "\n",
        "sampled_tokens = tf.random.categorical(\n",
        "    logits=decoder_result.logits[:, 0, :], \n",
        " \n",
        "    num_samples=1, \n",
        "    seed=dataset_config['random_seed'])\n",
        "sampled_tokens = tf.squeeze(sampled_tokens, axis=-1).numpy()\n",
        "\n",
        "first_word = list(vocab[sampled_tokens])\n",
        "first_word[:5]"
      ],
      "metadata": {
        "id": "Y2ixRaJZn271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cec094-9261-42c7-c092-988ac8614897"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['videoconferencing', 'kindling', 'meeting', 'supporters', 'poplar']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training for QG"
      ],
      "metadata": {
        "id": "qIoySQKuIGlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Loss\n",
        "\n",
        "The **QG** task is defined as finding $\\hat{y}$ such that:\n",
        "$$\n",
        "\\hat{y} = \\arg{\\max_y P(y|x)}  \n",
        "$$\n",
        "where $P(y|x)$ is the conditional log-likelihood of the predicted question sentence $y$ given the input $x$. Du et al. shown that the conditional probability could be factorized in:\n",
        "$$\n",
        "P(y|x) = \\prod_{t=1}^{|y|} P(y_t|x, y_{<t})\n",
        "$$\n",
        "where the probability of each $y_t$ is predicted based on all the words that have been generated upon time $t$, namely $y_{<t}$."
      ],
      "metadata": {
        "id": "qyRA2RxZNsx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'conditional_ll_loss'\n",
        "\n",
        "    # The loss needs to work with logits since the decoder is outputting the most probable token\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True,\n",
        "        reduction='none'\n",
        "    )\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch\n",
        "    # Shape of y_true = (batch_size, max_length_question)\n",
        "    # Shape of y_pred = (batch_size, max_length_question, vocab_size)\n",
        "    loss = self.loss(y_true=y_true, y_pred=y_pred)\n",
        "    \n",
        "    # Mask of the losses on the padding\n",
        "    mask = tf.math.not_equal(y_true, 0)\n",
        "    loss = tf.boolean_mask(loss, mask)\n",
        "    loss = tf.reduce_sum(loss)\n",
        "\n",
        "    # Return the total\n",
        "    return loss"
      ],
      "metadata": {
        "id": "IP_UunM3MUtF"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 QG model and training step implementation\n",
        "\n",
        "The training step should:\n",
        "1. Run the encoder on the `input_tokens` to get the `encoder_outputs`, `hidden_state` and `cell_state`. "
      ],
      "metadata": {
        "id": "iwLiPsCyNuor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QGeneratorTrainer(tf.keras.Model):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_dimension,\n",
        "               embedding_matrix,\n",
        "               units,\n",
        "               batch_size,\n",
        "               max_length_context,\n",
        "               max_length_question,\n",
        "               use_tf_function=True):\n",
        "    \"\"\"\n",
        "    Prepare the model for the training. It builds the both the encoder and the decoder.\n",
        "    Also it defines a wrapper to use the tf.function compilation for the tensorflow computational\n",
        "    graph.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(\n",
        "        vocab_size,\n",
        "        embedding_matrix,\n",
        "        embedding_dimension,\n",
        "        units,\n",
        "        batch_size,\n",
        "        max_length_context)\n",
        "\n",
        "    self.decoder = Decoder(\n",
        "        vocab_size,\n",
        "        embedding_matrix,\n",
        "        embedding_dimension,\n",
        "        units, \n",
        "        batch_size,\n",
        "        max_length_context,\n",
        "        max_length_question,\n",
        "        )\n",
        "    \n",
        "    self.use_tf_function = use_tf_function\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    \"\"\"\n",
        "    Wrapper that switches on and off the tf.function compilation for performance, see the \n",
        "    tensorflow documentation for the computation graph.\n",
        "    \"\"\"\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)\n",
        "\n",
        "  @tf.function\n",
        "  def _tf_train_step(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "\n",
        "  def _train_step(self, inputs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # Extract context and target\n",
        "    context, question = inputs\n",
        "    max_question_length = question.shape[1]\n",
        "\n",
        "    # Generate teh mask for both the context and the question\n",
        "    context_mask = self.__get_mask(context)\n",
        "    question_mask = self.__get_mask(question)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Encode the input\n",
        "      encoder_output, encoder_state = self.encoder(context)\n",
        "\n",
        "      # The decoder should be initialized with the encoder last state \n",
        "      decoder_state = encoder_state\n",
        "      loss = tf.constant(0.0)\n",
        "      t = 0\n",
        "\n",
        "      # Reference :- https://www.tensorflow.org/guide/function\n",
        "      # We have to run the decoder for all the length of the question \n",
        "      while t < max_question_length - 1:\n",
        "        # We have to pass two tokens:\n",
        "        #   1. the token at time step t, namely the token in which we need to start run the decoder \n",
        "        #   2. the token at time step t+1, that is the next token in the sequence that needs to be compared with\n",
        "        new_token = tf.gather(question, t, axis=1)\n",
        "        target_token = tf.gather(question, t+1, axis=1)\n",
        "\n",
        "        step_loss, decoder_state = self.__run_decoder(\n",
        "            (new_token, target_token),\n",
        "            context_mask,\n",
        "            encoder_output,\n",
        "            decoder_state)\n",
        "        \n",
        "        loss = loss + step_loss\n",
        "        t = t + 1\n",
        "\n",
        "      # Average the loss for all the legit tokens\n",
        "      avg_loss = loss / tf.math.reduce_sum(tf.cast(question_mask, dtype=loss.dtype))\n",
        "\n",
        "    # Apply an optimization step\n",
        "    tr_variables = self.trainable_variables\n",
        "    grads = tape.gradient(avg_loss, tr_variables)\n",
        "    \n",
        "    # Apply some clipping, by norm as written in the paper\n",
        "    grads = [tf.clip_by_norm(g, 5.0) for g in grads]\n",
        "    self.optimizer.apply_gradients(zip(grads, tr_variables))\n",
        "\n",
        "    return {f'batch_loss': avg_loss}\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def __run_decoder(self, \n",
        "                    tokens, \n",
        "                    context_mask, \n",
        "                    encoder_output, \n",
        "                    decoder_state):\n",
        "    \"\"\"\n",
        "    Run a single iteration of the decoder and computers the incremental loss between the\n",
        "    produced token and the token in the target input.\n",
        "\n",
        "    \"\"\"\n",
        "    new_token, target_token = tokens\n",
        "    \n",
        "    # Run the decoder one time\n",
        "    decoder_result, decoder_state = self.decoder(\n",
        "        inputs = DecoderInput(\n",
        "            new_token=new_token,\n",
        "            enc_output=encoder_output,\n",
        "            mask=context_mask),\n",
        "        state = decoder_state)\n",
        "  \n",
        "    y_true = target_token\n",
        "    y_pred = decoder_result.logits\n",
        "\n",
        "    step_loss = self.loss(y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "    return step_loss, decoder_state\n",
        "\n",
        "  def __get_mask(self, tokens): return tf.math.not_equal(tokens, 0)"
      ],
      "metadata": {
        "id": "8xSn_StMq9cx"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_model = QGeneratorTrainer(**encoder_config, \n",
        "            max_length_question=decoder_config['max_length_question'],\n",
        "            embedding_matrix=embedding_matrix,\n",
        "            use_tf_function=True)\n",
        "\n",
        "trainer_config['loss'] = MaskedLoss()\n",
        "\n",
        "qg_model.compile(\n",
        "    optimizer=trainer_config['optimizer'],\n",
        "    loss=trainer_config['loss']\n",
        ")"
      ],
      "metadata": {
        "id": "zwKc0rvrIWkg"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 Simple Training\n",
        "The first call with `use_tf_function=True` will be slow since it has to trace the function. So be patient or try `use_tf_function=False` 😀"
      ],
      "metadata": {
        "id": "SPSDqU3_3nOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataset.train))\n",
        "qg_model.train_step(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf5JzL9T47Ha",
        "outputId": "83d1eb6b-0841-4628-bf87-acdf4392918d"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method QGeneratorTrainer._train_step of <__main__.QGeneratorTrainer object at 0x7f98bf3dc690>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method QGeneratorTrainer._train_step of <__main__.QGeneratorTrainer object at 0x7f98bf3dc690>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=9.508118>}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses = []\n",
        "for n in tqdm(range(10)):\n",
        "  # print('.', end='')\n",
        "  logs = qg_model.train_step(next(iter(dataset.train)))\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)\n",
        "print()\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "E0ZatZ4g-5iq",
        "outputId": "a70276e8-0fae-4cf4-cd78-f59d076f7a2a"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:10<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[9.491358, 9.521131, 9.521131, 9.536566, 9.508117, 9.514298, 9.552709, 9.509671, 9.524867, 9.47035]\n",
            "CPU times: user 7.63 s, sys: 5.19 s, total: 12.8 s\n",
            "Wall time: 10.8 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Checkpoints\n",
        "\n",
        "See [Manual Checkpointing](https://www.tensorflow.org/guide/checkpoint)."
      ],
      "metadata": {
        "id": "x6uDOVpginU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"tf_ckpt\")"
      ],
      "metadata": {
        "id": "gEMKO8azio4k"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_iterator = iter(dataset.train) \n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "manager = tf.train.CheckpointManager(checkpoint,\n",
        "                                     checkpoint_prefix,\n",
        "                                     max_to_keep=3)"
      ],
      "metadata": {
        "id": "5tNJR_fRi7qd"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Train the model"
      ],
      "metadata": {
        "id": "fF8BfykX5faH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key) -> None:\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_ends(self, n, logs):\n",
        "    self.logs.append(logs[self.key])"
      ],
      "metadata": {
        "id": "uhSLln405mfy"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_loss = BatchLogs('batch_loss')\n",
        "history = qg_model.fit(dataset.train, epochs=trainer_config['epochs'], callbacks=[batch_loss], verbose='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ys97OwVn61UT",
        "outputId": "ec8a6b7f-66c5-43a1-9488-37e3dd8492b5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "  1/112 [..............................] - ETA: 10:22 - batch_loss: 9.5173"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-e6f8b73dc75b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchLogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Inference for QG\n",
        "In this section we will provide the class and the methods for the inference part. More specifically, both auxiliary and inferencing methods:\n",
        "1. `token_to_string()`:\n",
        "2. `string_to_token()`:\n",
        "3. `create_mask()`:\n",
        "4. `temperature_sampling()`:\n",
        "5. `generate_question()`:"
      ],
      "metadata": {
        "id": "ezgR7c68_0nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QGeneratorInference(tf.Module):\n",
        "  def __init__(self, encoder, decoder, tokenizer, word_to_idx):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.tokenizer = tokenizer\n",
        "    self.word_to_idx = word_to_idx\n",
        "   \n",
        "    self.result_tokens = None\n",
        "    self.result_text = None\n",
        "    self.token_mask = self.create_mask()\n",
        "\n",
        "    self.start_idx = word_to_idx['<sos>']\n",
        "    self.end_idx = word_to_idx['<eos>']\n",
        "    self.use_tf_function = False\n",
        "\n",
        "  def token_to_string(self, result_tokens: tf.Tensor):  \n",
        "    \"\"\"\n",
        "    This method converts token IDs to text by using a given mapping.\n",
        "    \"\"\"\n",
        "    list_tokens = result_tokens.numpy().tolist()\n",
        "    list_text = self.tokenizer.sequences_to_texts(list_tokens)\n",
        "    list_text = tf.convert_to_tensor([list_text])\n",
        "    result_text = tf.strings.reduce_join(list_text, axis=0, separator=' ')\n",
        "    result_text = tf.strings.strip(result_text)\n",
        "    \n",
        "    self.result_tokens = result_tokens\n",
        "    self.result_text = result_text\n",
        "    return result_text\n",
        "\n",
        "  def string_to_token(self, result_str: tf.Tensor):\n",
        "    \"\"\"\n",
        "    This method converts texts to token IDs by using a given mapping.\n",
        "    \"\"\"  \n",
        "    list_str = [s.decode(\"utf-8\") for s in result_str.numpy().tolist()]\n",
        "    list_tokens = self.tokenizer.texts_to_sequences(list_str)\n",
        "    list_tokens = tf.convert_to_tensor(list_tokens, dtype=tf.int64)\n",
        "    result_tokens = tf.squeeze(tf.split(list_tokens, num_or_size_splits=list_tokens.shape[0], axis=0), axis=1)\n",
        "\n",
        "    return result_tokens\n",
        "  \n",
        "  def create_mask(self):\n",
        "    \"\"\"\n",
        "    This method creates a mask for the padding, the unknwon words and the start/ending tokens.\n",
        "    \"\"\"\n",
        "    masked_words = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
        "    token_mask_ids = [self.tokenizer.word_index[mask] for mask in masked_words]\n",
        "\n",
        "    token_mask = np.zeros(shape=(len(self.word_to_idx),), dtype=bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    return token_mask\n",
        "\n",
        "  def temperature_sampling(self, logits, temperature=0.5):\n",
        "    \"\"\"\n",
        "\n",
        "    For the temperature choice see here:\n",
        "      Reference :- https://nlp.stanford.edu/blog/maximum-likelihood-decoding-with-rnns-the-good-the-bad-and-the-ugly/\n",
        "    \"\"\"\n",
        "    # First of all we use broadcast the generated mask to the expected logits' shape\n",
        "    # token_mask shape: (batch_size, timestep, vocab_size)\n",
        "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    # The logits for all the tokens that have to not be used are set top -1.0\n",
        "    logits = tf.where(token_mask, -1.0, logits)\n",
        "\n",
        "    # Freezing function\n",
        "    # Higher temperature -> greater variety\n",
        "    # Lower temperature -> grammatically correct\n",
        "    if temperature == 0.0:\n",
        "      # the freezing function is the argmax\n",
        "      new_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "      # the freezing function now scales the logits.\n",
        "      # for temperature == 1.0 is the identity function\n",
        "      logits = tf.squeeze(logits, axis=1)\n",
        "      new_token = tf.random.categorical(logits/temperature, num_samples=1)\n",
        "    return new_token\n",
        "\n",
        "  def predict(self, inputs, max_length):\n",
        "    \"\"\"\n",
        "    Wrapper that switches on and off the tf.function compilation for performance, see the \n",
        "    tensorflow documentation for the computation graph.\n",
        "    \"\"\"\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_generate_question(inputs, max_length)\n",
        "    else:\n",
        "      return self._generate_question(inputs, max_length)\n",
        "\n",
        "  @tf.function\n",
        "  def _tf_generate_question(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "\n",
        "  def _generate_question(self, \n",
        "                        inputs,\n",
        "                        max_length,\n",
        "                        return_attention=True,\n",
        "                        temperature=0.5):\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "    # Similarly for what it has been done in the train step\n",
        "    encoder_output, encoder_state = self.encoder(inputs)\n",
        "    decoder_state = encoder_state\n",
        "\n",
        "    # Generate the first token of each sentence, that is the <sos> token\n",
        "    new_token = tf.fill([batch_size, 1], self.start_idx)\n",
        "\n",
        "    result_tokens = []\n",
        "    attention = []\n",
        "    timestep = 0\n",
        "    while timestep < max_length:\n",
        "      timestep = timestep + 1\n",
        "      \n",
        "      # Decode the token at the next timestep\n",
        "      decoder_result, decoder_state = self.decoder(\n",
        "        inputs = DecoderInput(\n",
        "            new_token=new_token,\n",
        "            enc_output=encoder_output,\n",
        "            mask=(inputs != 0)),\n",
        "        state = decoder_state)\n",
        "      \n",
        "      attention.append(decoder_result.attention_weights)\n",
        "\n",
        "      # Sample the new token accordingly to the distribution produced by the decoder\n",
        "      new_token = self.temperature_sampling(decoder_result.logits, temperature)\n",
        "\n",
        "      # if a sequence has reached <eos> set it as done\n",
        "      \n",
        "      result_tokens.append(new_token)\n",
        "    \n",
        "    #\n",
        "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "    result_text = self.token_to_string(result_tokens)\n",
        "\n",
        "    attention_stack = tf.concat(attention, axis=-1)\n",
        "\n",
        "    if return_attention:\n",
        "      attention_stack = tf.concat(attention, axis=1)\n",
        "      return {'text': result_text, 'attention': attention_stack}\n",
        "    else:\n",
        "      return {'text': result_text}"
      ],
      "metadata": {
        "id": "gn2NTxAq_2sy"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_generator = QGeneratorInference(qg_model.encoder, qg_model.decoder, dataset_creator.tokenizer, word_to_idx[1])"
      ],
      "metadata": {
        "id": "1Q2pWJ5YDfqi"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_logits = tf.random.normal([5, 1, len(word_to_idx[1])])\n",
        "example_output_tokens = qg_generator.temperature_sampling(example_logits, temperature=1.0)"
      ],
      "metadata": {
        "id": "fklYEd1e6XOb"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_generator.predict(example_output_tokens, max_length=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RO-7QCL_MSc",
        "outputId": "5b53dfb0-8943-4991-f374-05f62eb8eecb"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention': <tf.Tensor: shape=(5, 10, 1), dtype=float32, numpy=\n",
              " array([[[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.]],\n",
              " \n",
              "        [[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.]],\n",
              " \n",
              "        [[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.]],\n",
              " \n",
              "        [[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.]],\n",
              " \n",
              "        [[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.]]], dtype=float32)>,\n",
              " 'text': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              " array([b'rattlers cafl eugenio convergence dimensional haas generate arch parisian alister',\n",
              "        b'mailto 015 leaving network volvo 1024 597 bell bangkok jaered',\n",
              "        b'kaliningrad guez curing archived provisioning sikhs clemente module nemaa cixi',\n",
              "        b'octave albrecht functional lj skiing talf recover counterclaims evenings knows',\n",
              "        b'natura lamu snowpack contradiction alexandrian tradtionally migrants collectors exposure rajola'],\n",
              "       dtype=object)>}"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ha1sP-HiWgeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}