{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hlpy-ayWoEHa",
        "r7qxjGzKJM2w",
        "kx2f7Nn_4en9",
        "wjVfZgIIf1RV",
        "fbjSxPGcFud_",
        "SPSDqU3_3nOg",
        "x6uDOVpginU0",
        "fF8BfykX5faH",
        "ezgR7c68_0nv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erhtric/NeuralQuestionGenerationNLP/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the main file: its purpouse is to collect all the code coming from the coding pipeline."
      ],
      "metadata": {
        "id": "8OU-wpGL18xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U tensorflow-addons\n",
        "!pip install -q \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htbwd0W_Y9IC",
        "outputId": "39ce4338-9585-474e-fea8-9d002c70a40a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 57.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "import re\n",
        "import os\n",
        "import typing\n",
        "from typing import Any, Tuple, List, NamedTuple\n",
        "import spacy\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "from gensim.models import KeyedVectors\n",
        "import seaborn as sns\n",
        "from itertools import chain\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "#import tensorflow_addons as tfa\n",
        "import tensorflow_text as tf_text\n",
        "from tensorflow import keras\n",
        "from keras.layers import (\n",
        "    Layer, \n",
        "    Embedding, \n",
        "    LSTM, \n",
        "    Dense, \n",
        "    Bidirectional, \n",
        "    Input, \n",
        "    AdditiveAttention)\n",
        "\n",
        "import nltk\n",
        "from nltk import punkt, pos_tag, ne_chunk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLvONYDvKAHz",
        "outputId": "ee7d011d-116d-47be-a5be-61d33c0a0c28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CIZdy1hp14x8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21730d5c-2a11-48ad-9842-190aa4d98ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commands to prepare the folder to accomodate data."
      ],
      "metadata": {
        "id": "UqKVWPel_ybt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP/Project/Testing folder/Eric\n",
        "%pwd\n",
        "%mkdir data\n",
        "%mkdir training_checkpoints\n",
        "\n",
        "# disable chained assignments to avoid annoying warning\n",
        "pd.options.mode.chained_assignment = None "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKVGy7JPJCoi",
        "outputId": "ccedf027-0dc5-4d59-e0c3-152c7499ace6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1cVw6eUwM-dRL9BhqtXULyOqeXDrYkwmH/NLP/Project/Testing folder/Eric\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘training_checkpoints’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print({tf.__version__})"
      ],
      "metadata": {
        "id": "-ePFW3UcrVtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88bc747-49c9-4a01-95f7-ade7395b6760"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2.8.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is for the `configuration.json` file: "
      ],
      "metadata": {
        "id": "2hyzKyj_-GjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "units = 600\n",
        "\n",
        "dataset_config = {\n",
        "    # 'num_examples': 18896,\n",
        "    'num_examples': 9000,\n",
        "    'num_words_context': 45000,\n",
        "    'num_words_question': 28000,\n",
        "    'buffer_size': 32000,\n",
        "    'batch_size': batch_size,\n",
        "    'random_seed': 13,\n",
        "}\n",
        "\n",
        "encoder_config = {\n",
        "    'vocab_size': None,\n",
        "    'embedding_dimension': 300,\n",
        "    'units': units,\n",
        "    'batch_size': batch_size,\n",
        "    'max_length_context': None\n",
        "}\n",
        "\n",
        "decoder_config = {\n",
        "    'vocab_size': None,\n",
        "    'embedding_dimension': 300,\n",
        "    'units': units,\n",
        "    'batch_size': batch_size,\n",
        "    'max_length_question': None,\n",
        "    'max_length_context': None\n",
        "}\n",
        "\n",
        "trainer_config = {\n",
        "    'epochs': 3,\n",
        "    'optimizer': tf.optimizers.Adam(learning_rate=1e-3),\n",
        "    'loss': tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "}\n",
        "\n",
        "path = {\n",
        "    'training_json_path': \"./data/training_set.json\",\n",
        "    'save_pkl_path': \"./data/squadv2.pkl\"\n",
        "}"
      ],
      "metadata": {
        "id": "5bS3uLkE-Mvf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data handling and Pre-processing\n",
        "\n",
        "\n",
        "Things to do:\n",
        "1. Add to each sentence $x$ a start of sequence `<SOS>` tag and end of sequence `<EOS>` tag,\n",
        "2. Clean the sentences by removing special chars,\n",
        "3. Perform other preprocessing steps,\n",
        "4. Create a **vocabulary** with a word-to-index and index-to-word mappings by using a **tokenizer**, \n",
        "5. Extract the sentences that contain an answer and use them as input features, whereas the question will be our target\n",
        "6. Pad each context to maximum length.\n",
        "\n",
        "The resulting data that will be used hereinafter will be of type `tf.data.Dataset`. "
      ],
      "metadata": {
        "id": "sFBKCIE3Jxf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(NamedTuple):\n",
        "  \"\"\"\n",
        "  This class represent a a 3-way split processed dataset. \n",
        "  \"\"\"\n",
        "  # Reference :- https://github.com/topper-123/Articles/blob/master/New-interesting-data-types-in-Python3.rst\n",
        "  train: tf.data.Dataset\n",
        "  val: tf.data.Dataset\n",
        "  test: tf.data.Dataset\n",
        "\n",
        "class SQuAD:\n",
        "  def __init__(self):\n",
        "    self.random_seed = None\n",
        "    self.squad_df = None\n",
        "    self.preproc_squad_df = None\n",
        "    self.tokenizer = None\n",
        "    self.buffer_size = 0\n",
        "    self.batch_size = 0\n",
        "\n",
        "  def __call__(self,\n",
        "           num_examples, \n",
        "           buffer_size, \n",
        "           batch_size, \n",
        "           random_seed,\n",
        "           training_json_path,\n",
        "           save_pkl_path,\n",
        "           num_words_context=None,\n",
        "           num_words_question=None,\n",
        "           tokenized=True,\n",
        "           pos_ner_tag=True,\n",
        "           tensor_type=True):\n",
        "    \"\"\"The call() method loads the SQuAD dataset, preprocess it and optionally it returns \n",
        "    it tokenized. Moreover it also perform a 3-way split.\n",
        "\n",
        "    Args:\n",
        "        num_examples (int): number of examples to be taken from the original SQuAD dataset\n",
        "        num_words (int): the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept. \n",
        "        buffer_size (int): buffer size for the shuffling operation\n",
        "        batch_size (int): size of the batches\n",
        "        tokenized (boolean): specifies if the context and question data should be both tokenized\n",
        "        pos_ner_tag (boolean):\n",
        "        tensro_type (boolean): \n",
        "\n",
        "    Returns (depending on the input parameters):\n",
        "        pd.DataFrame: training dataset\n",
        "        pd.DataFrame: validation dataset\n",
        "        pd.DataFrame: testing dataset\n",
        "          OR\n",
        "        NamedTuple: dataset, (dict, dict, dict)\n",
        "    \"\"\"\n",
        "    self.random_seed = random_seed\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.training_json_path = training_json_path\n",
        "    self.save_pkl_path = save_pkl_path\n",
        "    self.pos_ner_tag = pos_ner_tag\n",
        "\n",
        "    # Load dataset from file\n",
        "    self.load_dataset(num_examples)\n",
        "    # Extract answer\n",
        "    self.extract_answer()\n",
        "    # Preprocess context and question\n",
        "    self.preprocess()\n",
        "    \n",
        "    # Perform splitting\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = self.split_train_val(self.preproc_squad_df)\n",
        "    \n",
        "    if self.pos_ner_tag: \n",
        "      pass\n",
        "\n",
        "    # Initialize Tokenizer for the source: in our case the context phrases\n",
        "    # alternatively TextVectorization \n",
        "    self.tokenizer_context = tf.keras.preprocessing.text.Tokenizer(filters='', \n",
        "                                                                   oov_token='<unk>',\n",
        "                                                                   num_words=num_words_context)\n",
        "    # initialize also for the target, namely the question phrases\n",
        "    self.tokenizer_question = tf.keras.preprocessing.text.Tokenizer(filters='', \n",
        "                                                                   oov_token='<unk>',\n",
        "                                                                   num_words=num_words_question)\n",
        "\n",
        "    if tokenized:\n",
        "      X_train_tokenized, word_to_idx_train_context = self.__tokenize_context(X_train)\n",
        "      y_train_tokenized, word_to_idx_train_question = self.__tokenize_question(y_train)\n",
        "\n",
        "      X_val_tokenized, word_to_idx_val_context = self.__tokenize_context(X_val)\n",
        "      y_val_tokenized, word_to_idx_val_question = self.__tokenize_question(y_val)\n",
        "\n",
        "      X_test_tokenized, word_to_idx_test_context = self.__tokenize_context(X_test)\n",
        "      y_test_tokenized, word_to_idx_test_question = self.__tokenize_question(y_test)\n",
        "\n",
        "      word_to_idx_context = (word_to_idx_train_context, word_to_idx_val_context, word_to_idx_test_context)\n",
        "      word_to_idx_question = (word_to_idx_train_question, word_to_idx_val_question, word_to_idx_test_question)\n",
        "      \n",
        "      if tensor_type:\n",
        "        # Returns tf.Data.Dataset objects (tokenized)\n",
        "        train_dataset = self.to_tensor(X_train_tokenized, y_train_tokenized)\n",
        "        val_dataset = self.to_tensor(X_val_tokenized, y_val_tokenized)\n",
        "        test_dataset = self.to_tensor(X_test_tokenized, y_test_tokenized)\n",
        "\n",
        "        dataset = Dataset(\n",
        "            train=train_dataset, \n",
        "            val=val_dataset,\n",
        "            test=test_dataset)\n",
        "\n",
        "        return dataset, word_to_idx_context, word_to_idx_question\n",
        "      else:\n",
        "        # Returns pd.DataFrame objects (tokenized)\n",
        "        return X_train_tokenized, y_train_tokenized, X_val_tokenized, y_val_tokenized, X_test_tokenized, y_test_tokenized\n",
        "    else:\n",
        "      return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "  def load_dataset(self, num_examples):\n",
        "    \"\"\"\n",
        "    Extract the dataset from the json file. Already grouped by title.\n",
        "\n",
        "    :param path: [Optional] specifies the local path where the training_set.json file is located\n",
        "\n",
        "    :return\n",
        "        - the extracted dataset in a dataframe format\n",
        "    \"\"\"\n",
        "    if os.path.exists(self.save_pkl_path):\n",
        "      print('File already exists! Loading from .pkl...\\n')\n",
        "      self.squad_df = pd.read_pickle(self.save_pkl_path)\n",
        "      self.squad_df = self.squad_df[:num_examples]\n",
        "    else:\n",
        "      print('Loading from .json...\\n')\n",
        "      with open(self.training_json_path) as f:\n",
        "          data = json.load(f)\n",
        "\n",
        "      df_array = []\n",
        "      for current_subject in data['data']:\n",
        "          title = current_subject['title']\n",
        "\n",
        "          for current_context in current_subject['paragraphs']:\n",
        "              context = current_context['context']\n",
        "\n",
        "              for current_question in current_context['qas']:\n",
        "                  question = current_question['question']\n",
        "                  id = current_question['id']\n",
        "\n",
        "              for answer_text in current_question['answers']:\n",
        "                    answer = answer_text['text']\n",
        "                    answer_start = answer_text['answer_start']\n",
        "                    record = { \"id\": id,\n",
        "                                \"title\": title,\n",
        "                                \"context\": context,\n",
        "                                \"question\": question,\n",
        "                                \"answer_start\": answer_start,\n",
        "                                \"answer\": answer\n",
        "                                }\n",
        "\n",
        "              df_array.append(record)\n",
        "      \n",
        "      # Save file\n",
        "      pd.to_pickle(pd.DataFrame(df_array), self.save_pkl_path)\n",
        "      self.squad_df = pd.DataFrame(df_array)[:num_examples]\n",
        "\n",
        "  def preprocess(self):\n",
        "    df = self.squad_df.copy()\n",
        "\n",
        "    # Pre-processing context\n",
        "    context = list(df.context)\n",
        "    preproc_context = []\n",
        "\n",
        "    for c in context:\n",
        "      c = self.__preprocess_sentence(c, question=False)\n",
        "      preproc_context.append(c)\n",
        "    \n",
        "    df.context = preproc_context\n",
        "\n",
        "    # Pre-processing questions\n",
        "    question = list(df.question)\n",
        "    preproc_question = []\n",
        "\n",
        "    for q in question:\n",
        "      q = self.__preprocess_sentence(q, question=True)\n",
        "      preproc_question.append(q)\n",
        "    \n",
        "    df.question = preproc_question\n",
        "\n",
        "    # Remove features that are not useful\n",
        "    df = df.drop(['id'], axis=1)\n",
        "    self.preproc_squad_df = df\n",
        "\n",
        "  def __preprocess_sentence(self, sen, question):\n",
        "    # Creating a space between a word and the punctuation following it\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    sen = re.sub(r\"([?.!,¿])\", r\" \\1 \", sen)\n",
        "    sen = re.sub(r'[\" \"]+', \" \", sen)\n",
        "\n",
        "    # Replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sen = re.sub(r\"[^a-zA-Z0-9?.!,¿]+\", \" \", sen)\n",
        "\n",
        "    sen = sen.strip()\n",
        "\n",
        "    # Adding a start and an end token to the sentence so that the model know when to \n",
        "    # start and stop predicting.\n",
        "    # if not question: sen = '<SOS> ' + sen + ' <EOS>'\n",
        "    sen = '<SOS> ' + sen + ' <EOS>'\n",
        "    return sen\n",
        "\n",
        "  def __answer_start_end(self, df):\n",
        "    \"\"\"\n",
        "    Creates a list of starting indexes and ending indexes for the answers.\n",
        "\n",
        "    :param df: the target Dataframe\n",
        "\n",
        "    :return: a dataframe containing the start and the end indexes foreach answer (ending index is excluded).\n",
        "\n",
        "    \"\"\"\n",
        "    start_idx = df.answer_start\n",
        "    end_idx = [start + len(list(answer)) for start, answer in zip(list(start_idx), list(df.answer))]\n",
        "    return pd.DataFrame(list(zip(start_idx, end_idx)), columns=['start', 'end'])\n",
        "\n",
        "  def split_train_val(self, df, train_size=0.8):\n",
        "    \"\"\"\n",
        "    This method splits the dataframe in training and test sets, or eventually, in training, validation and test sets.\n",
        "\n",
        "    Args\n",
        "        :param df: the target Dataframe\n",
        "        :param random_seed: random seed used in the splits\n",
        "        :param train_size: represents the absolute number of train samples\n",
        "        :param val: boolean for choosing between a 3-way split or 2-way one.\n",
        "\n",
        "    Returns:\n",
        "        - Data and labels for training, validation and test sets if val is True \n",
        "        - Data and labels for training and test sets if val is False \n",
        "\n",
        "    \"\"\"\n",
        "    # Maybe we have also to return the index for the starting answer\n",
        "    X = df.drop(['answer_start', 'question', 'answer'], axis=1).copy()\n",
        "    idx = self.__answer_start_end(df)\n",
        "    X['start'] = idx['start']\n",
        "    X['end'] = idx['end']\n",
        "    y = df['question']\n",
        "\n",
        "    # In the first step we will split the data in training and remaining dataset\n",
        "    splitter = GroupShuffleSplit(train_size=train_size, n_splits=2, random_state=self.random_seed)\n",
        "    split = splitter.split(X, groups=X['title'])\n",
        "    train_idx, rem_idx = next(split)\n",
        "\n",
        "    X_train = X.iloc[train_idx]\n",
        "    y_train = y.iloc[train_idx]\n",
        "    X_rem = X.iloc[rem_idx]\n",
        "    y_rem = y.iloc[rem_idx]\n",
        "\n",
        "\n",
        "    # Val and test test accounts for 10% of the total data. Both 5%.\n",
        "    splitter = GroupShuffleSplit(train_size=train_size, n_splits=2, random_state=self.random_seed)\n",
        "    split = splitter.split(X_rem, groups=X_rem['title'])\n",
        "    val_idx, test_idx = next(split)\n",
        "\n",
        "    X_val = X_rem.iloc[val_idx]\n",
        "    y_val = y_rem.iloc[val_idx]\n",
        "\n",
        "    X_test = X_rem.iloc[test_idx]\n",
        "    y_test = y_rem.iloc[test_idx]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "  def __tokenize_context(self, X):\n",
        "    context = X.context\n",
        "    self.tokenizer_context.fit_on_texts(context)\n",
        "    context_tf = self.tokenizer_context.texts_to_sequences(context)\n",
        "\n",
        "    # context_lengths = [len(seq) for seq in context_tf]\n",
        "    # sns.boxplot(context_lengths)\n",
        "\n",
        "    context_tf_pad = tf.keras.preprocessing.sequence.pad_sequences(context_tf, padding='post')\n",
        "\n",
        "    for i, _ in enumerate(context):\n",
        "      X['context'].iloc[i] = context_tf_pad[i]\n",
        "\n",
        "    # Add the padding\n",
        "    self.tokenizer_context.word_index['<pad>'] = 0\n",
        "    self.tokenizer_context.index_word[0] = '<pad>'\n",
        "\n",
        "    return X, self.tokenizer_context.word_index\n",
        "\n",
        "  def __tokenize_question(self, y):\n",
        "    question = y\n",
        "    self.tokenizer_question.fit_on_texts(question)\n",
        "    question_tf = self.tokenizer_question.texts_to_sequences(question)\n",
        "\n",
        "    # question_lengths = [len(seq) for seq in question_tf]\n",
        "    # sns.boxplot(question_lengths)\n",
        "    \n",
        "    # See also tf.data.Dataset.padding_batch\n",
        "    question_tf_pad = tf.keras.preprocessing.sequence.pad_sequences(question_tf, padding='post')\n",
        "\n",
        "    for i, _ in enumerate(question):\n",
        "      y.iloc[i] = question_tf_pad[i]\n",
        "\n",
        "    # Add the padding\n",
        "    self.tokenizer_question.word_index['<pad>'] = 0\n",
        "    self.tokenizer_question.index_word[0] = '<pad>'\n",
        "\n",
        "    return y, self.tokenizer_question.word_index\n",
        "\n",
        "  def extract_answer(self):\n",
        "    df = self.squad_df.copy()\n",
        "    start_end = self.__answer_start_end(df)\n",
        "    context = list(df.context)\n",
        "    \n",
        "    selected_sentences = []\n",
        "    for i, par in enumerate(context):\n",
        "      sentences = sent_tokenize(par)\n",
        "      start = start_end.iloc[i].start\n",
        "      end = start_end.iloc[i].end      \n",
        "      right_sentence = \"\"\n",
        "      context_characters = 0\n",
        "\n",
        "      for j, sen in enumerate(sentences):\n",
        "        sen += ' '\n",
        "        context_characters += len(sen)\n",
        "        # If the answer is completely in the current sentence\n",
        "        if(start < context_characters and end <= context_characters):\n",
        "          right_sentence = sen\n",
        "          selected_sentences.append(right_sentence)\n",
        "          break\n",
        "        # the answer is in both the current and the next sentence\n",
        "        if(start < context_characters and end > context_characters):\n",
        "          right_sentence = sen + sentences[j+1]\n",
        "          selected_sentences.append(right_sentence)\n",
        "          break \n",
        "\n",
        "    self.squad_df.context = selected_sentences\n",
        "\n",
        "  def to_tensor(self, X, y):\n",
        "    X = X.context.copy()\n",
        "    y = y.copy()\n",
        "\n",
        "    # Reference:- https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (tf.cast(list(X), tf.int64), \n",
        "         tf.cast(list(y), tf.int64)))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "XyCKxqwRZelj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By calling the `SQuAD` constructor we create a dataset handling object which will be useful for future operations."
      ],
      "metadata": {
        "id": "iTXVdOGcZSCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_creator = SQuAD()"
      ],
      "metadata": {
        "id": "RfCYdZofJ866"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Preprocessed untokenized split"
      ],
      "metadata": {
        "id": "ZgeJckqZIufT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator.call(num_examples=dataset_creator.og_n_samples+1,\n",
        "#                                                                       num_words=None,\n",
        "#                                                                       BUFFER_SIZE=32000,\n",
        "#                                                                       BATCH_SIZE=64,\n",
        "#                                                                       random_seed=RANDOM_SEED,\n",
        "#                                                                       tokenized=False)\n",
        "\n",
        "# print(f'Set target: {X_train.columns.values}')\n",
        "\n",
        "# print(f'Train set samples: {X_train.shape[0]}')\n",
        "# print(f'Validation set samples: {X_val.shape[0]}')\n",
        "# print(f'Test set samples: {X_test.shape[0]}')\n",
        "\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator(**dataset_config, **path, tokenized=False)"
      ],
      "metadata": {
        "id": "TJFUuu2Y5hc-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Tokenized split"
      ],
      "metadata": {
        "id": "dndR7_CNI1jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Tensor Ready\n",
        "\n",
        "This is the data produced that we are most interested in. As we can see we will have:\n",
        "- a data structure `dataset` containing the training, validation and test set;\n",
        "- a tuple containing the word-to-token mappings for the training, validation and test set respectively."
      ],
      "metadata": {
        "id": "MvU7n1LboA6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "%%time\n",
        "dataset, word_to_idx_context, word_to_idx_question = dataset_creator(**dataset_config, **path, tokenized=True)\n",
        "\n",
        "max_length_context = dataset.train.element_spec[0].shape[1]\n",
        "max_length_question = dataset.train.element_spec[1].shape[1]\n",
        "\n",
        "print(f'Sentences max lenght: {max_length_context}')\n",
        "print(f'Questions max lenght: {max_length_question}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax999y7aI75Y",
        "outputId": "2d68a183-fcbc-4b57-adab-295eb52f62ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists! Loading from .pkl...\n",
            "\n",
            "Sentences max lenght: 389\n",
            "Questions max lenght: 40\n",
            "CPU times: user 10.9 s, sys: 402 ms, total: 11.3 s\n",
            "Wall time: 10.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing such `NamedTuple` data structure (cfr `dataset`) is pretty simple, namely in a:\n",
        "1. tuple-way by accessing it like a list, e.g. `train = dataset[0]`,\n",
        "2. object-way by calling the instance parameters, e.g. `train = dataset.train`.\n",
        "\n",
        "The other two returned values are the word to index mappings for the context and question words respectively. In order to refer to a specific split simply call:\n",
        "1. for the training dataset,\n",
        "2. for the validation dataset,\n",
        "3. for the test dataset,"
      ],
      "metadata": {
        "id": "W7hARM_R2Kod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training vocab size for the context: {len(word_to_idx_context[0])}')\n",
        "print(f'Training vocab size for the question: {len(word_to_idx_question[0])}')\n",
        "print()\n",
        "print(f'Validation vocab size for the context: {len(word_to_idx_context[1])}')\n",
        "print(f'Validation vocab size for the question: {len(word_to_idx_question[1])}')\n",
        "print()\n",
        "print(f'Test vocab size for the context: {len(word_to_idx_context[2])}')\n",
        "print(f'Test vocab size for the question: {len(word_to_idx_question[2])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obaRYgawxyXp",
        "outputId": "168e7a29-2850-4ebd-a491-7b2e3a630083"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training vocab size for the context: 23465\n",
            "Training vocab size for the question: 11342\n",
            "\n",
            "Validation vocab size for the context: 26136\n",
            "Validation vocab size for the question: 12672\n",
            "\n",
            "Test vocab size for the context: 26567\n",
            "Test vocab size for the question: 12892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Standard"
      ],
      "metadata": {
        "id": "hlpy-ayWoEHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset without tokenizing\n",
        "# %%time\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = dataset_creator.call(num_examples=dataset_creator.og_n_samples+1,\n",
        "#                      BUFFER_SIZE=32000,\n",
        "#                      BATCH_SIZE=64,\n",
        "#                      random_seed=RANDOM_SEED,\n",
        "#                      tokenized=True,\n",
        "#                      tensor_type=False)\n",
        "\n",
        "# print(f'\\nSet target: {X_train.columns.values}')\n",
        "\n",
        "# print(f'Train set samples: {X_train.shape[0]}')\n",
        "# print(f'Validation set samples: {X_val.shape[0]}')\n",
        "# print(f'Test set samples: {X_test.shape[0]}')"
      ],
      "metadata": {
        "id": "vJFBk-r8eIcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Original SQuAD dataset"
      ],
      "metadata": {
        "id": "r7qxjGzKJM2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original dataset\n",
        "# squad_df = dataset_creator.squad_df\n",
        "# print(f'[Info] SQuAD target: {list(squad_df.columns.values)}')\n",
        "# print(f'[Info] Shape: {squad_df.shape}')"
      ],
      "metadata": {
        "id": "9qhTAc5NErOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. GloVe and embedding matrix"
      ],
      "metadata": {
        "id": "kx2f7Nn_4en9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVe:\n",
        "  def __init__(self, embedding_dimension):\n",
        "    self.embedding_dimension = embedding_dimension\n",
        "\n",
        "    try:\n",
        "      self.embedding_model = KeyedVectors.load(f'./data/glove_model_{self.embedding_dimension}')\n",
        "    except FileNotFoundError:\n",
        "      print('[Warning] Model not found in local folder, please wait...')\n",
        "      self.embedding_model = self.load_glove()\n",
        "      self.embedding_model.save(f'./data/glove_model_{self.embedding_dimension}')  \n",
        "      print('Download finished. Model loaded!')\n",
        "\n",
        "  def load_glove(self):\n",
        "    \"\"\"\n",
        "    Loads a pre-trained GloVe embedding model via gensim library.\n",
        "\n",
        "    We have a matrix that associate words to a vector of a user-defined dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    download_path = \"glove-wiki-gigaword-{}\".format(self.embedding_dimension)\n",
        "\n",
        "    try:\n",
        "      emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "      print(\"Generic error when loading GloVe\")\n",
        "      print(\"Check embedding dimension\")\n",
        "      raise e\n",
        "\n",
        "    emb_model = gloader.load(download_path)\n",
        "    return emb_model\n",
        "\n",
        "  def build_embedding_matrix(self, word_to_idx, vocab_size: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the \n",
        "        dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, self.embedding_dimension), dtype=np.float32)\n",
        "    oov_count = 0\n",
        "    oov_words = []\n",
        "\n",
        "    # For each word which is not present in the vocabulary we assign a random vector, otherwise we take the GloVe embedding\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "      try:\n",
        "        embedding_vector = self.embedding_model[word]\n",
        "      except (KeyError, TypeError):\n",
        "        oov_count += 1\n",
        "        oov_words.append(word)\n",
        "        # embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "        embedding_vector = np.random.uniform(low=-0.05, \n",
        "                                             high=0.05, \n",
        "                                             size=self.embedding_dimension)\n",
        "\n",
        "      embedding_matrix[idx] = embedding_vector\n",
        "    \n",
        "    print(f'\\n[Debug] {oov_count} OOV words found!')\n",
        "    return embedding_matrix, oov_words"
      ],
      "metadata": {
        "id": "TRJ1NpSMqaJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to initialize the handler with the desidered `embedding_dimension`. Then to build the embedding matrix with the pre-trained GloVe embeddings simply call the `build_embedding_matrix` method."
      ],
      "metadata": {
        "id": "gk-z8A5y3cpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize the handler for GloVe\n",
        "glove_handler = GloVe(encoder_config['embedding_dimension'])\n",
        "\n",
        "# We will create the matrix by using only the words present in the training and validation set\n",
        "embedding_matrix, oov_words = glove_handler.build_embedding_matrix(\n",
        "    word_to_idx[1], \n",
        "    len(word_to_idx[1])+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUmvdCWGavSR",
        "outputId": "0014735c-51c2-4159-f6d6-690f8e631c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27511/27511 [00:00<00:00, 103836.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] 2034 OOV words found!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Definition"
      ],
      "metadata": {
        "id": "FF5Rtd4uqa_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_context_batch, example_question_batch = next(iter(dataset.train))"
      ],
      "metadata": {
        "id": "GjdRysIvPoLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1StCU2NBnniP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Encoder\n",
        "We will use a bidirectional LSTM to encode the sentence,\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\overrightarrow{b_t} &= \\overrightarrow{\\text{LSTM}}(x_t, \\overrightarrow{b_{t-1}})\\\\\n",
        "\\overleftarrow{b_t} &= \\overleftarrow{\\text{LSTM}}(x_t, \\overleftarrow{b_{t+1}})\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "where $\\overrightarrow{b_t}$ is the hidden state at time step $t$ for the forward pass LSTM and $\\overleftarrow{b_t}$ for the backward pass."
      ],
      "metadata": {
        "id": "wjVfZgIIf1RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               vocab_size, \n",
        "               embedding_matrix,\n",
        "               embedding_dimension, \n",
        "               units, \n",
        "               batch_size, \n",
        "               max_length_context,\n",
        "               **kwargs):\n",
        "    super(Encoder, self).__init__(**kwargs)\n",
        "    self.batch_size = tf.constant(batch_size)\n",
        "    self.max_length_context = tf.constant(max_length_context)\n",
        "\n",
        "    # Layers\n",
        "    self.inputs = Input(shape=(self.max_length_context,), name='encoder_input')\n",
        "    \n",
        "    self.embedding = Embedding(input_dim=vocab_size+1,\n",
        "                               output_dim=embedding_dimension,\n",
        "                               input_length=self.max_length_context,\n",
        "                               embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                               trainable=False,\n",
        "                               mask_zero=False,\n",
        "                               name='encoder_embedding_layer')\n",
        "    \n",
        "    # The LSTM forward pass\n",
        "    self.forward_lstm_layer = LSTM(units//2,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform',\n",
        "                                  use_bias=True,\n",
        "                                  input_shape=(self.max_length_context, embedding_dimension),\n",
        "                                  name='encoder_flstm_layer')\n",
        "    \n",
        "    # The LSTM backward pass\n",
        "    self.backward_lstm_layer = LSTM(units//2,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  go_backwards=True,\n",
        "                                  recurrent_initializer='glorot_uniform',\n",
        "                                  use_bias=True,\n",
        "                                  input_shape=(self.max_length_context, embedding_dimension),\n",
        "                                  name='encoder_blstm_layer')\n",
        "    \n",
        "    # The Bidirectional wrapper\n",
        "    self.bidirectional_lstm = Bidirectional(self.forward_lstm_layer, \n",
        "                                            backward_layer=self.backward_lstm_layer, \n",
        "                                            name='encoder_bi_lstm',\n",
        "                                            merge_mode='concat')\n",
        "    \n",
        "  def call(self, inputs, state=None):\n",
        "    # shape = (batch_size, max_length_context)\n",
        "    x = self.embedding(inputs)\n",
        "\n",
        "    # encoder_outputs shape = (batch_size, max_length_context, embedding_dimension)\n",
        "    # forward_h shape = (batch_size, units//2)\n",
        "    # forward_c shape = (batch_size, units//2)\n",
        "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = self.bidirectional_lstm(x, initial_state=state)\n",
        "    \n",
        "    # concat shape = (batch_size, units) \n",
        "    h_concat = tf.concat([forward_h, backward_h], axis=1)\n",
        "    c_concat = tf.concat([forward_c, backward_c], axis=1)\n",
        "    return encoder_outputs, (h_concat, c_concat)\n",
        "\n",
        "  ##### VISUALIZATION METHODS #####\n",
        "  # Reference :- https://stackoverflow.com/questions/61427583/how-do-i-plot-a-keras-tensorflow-subclassing-api-model\n",
        "  def build_graph(self):\n",
        "    x = Input(shape=(self.max_length_context,), batch_size=self.batch_size)\n",
        "    return tf.keras.Model(inputs=x, outputs=self.call(x))\n",
        "  \n",
        "  def plot_model(self):\n",
        "    return tf.keras.utils.plot_model(\n",
        "        self.build_graph(), \n",
        "        to_file='encoder.png', dpi=96,              \n",
        "        show_shapes=True, show_layer_names=True,  \n",
        "        expand_nested=False                       \n",
        "    )"
      ],
      "metadata": {
        "id": "GK6Kd1XvqK22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Test the encoder stack\n",
        "\n"
      ],
      "metadata": {
        "id": "fbjSxPGcFud_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_config['vocab_size'] = len(word_to_idx[1])\n",
        "encoder_config['max_length_context'] = dataset.train.element_spec[0].shape[1]\n",
        "\n",
        "encoder = Encoder(**encoder_config, embedding_matrix=embedding_matrix)\n",
        "encoder_outputs, encoder_state = encoder(inputs=example_context_batch)\n",
        "\n",
        "hidden_state, cell_state = encoder_state\n",
        "\n",
        "print(f'Decoder output shape: (batch_size, max_length_context, units): {encoder_outputs.shape}')\n",
        "print(f'Hidden state shape: (batch_size, units): {hidden_state.shape}')\n",
        "print(f'Cell state shape: (batch_size, units): {cell_state.shape}')"
      ],
      "metadata": {
        "id": "_ffteDMQyzmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b79af2-c314-41c6-bf33-27f08b26ef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, max_length_context, units): (64, 389, 600)\n",
            "Hidden state shape: (batch_size, units): (64, 600)\n",
            "Cell state shape: (batch_size, units): (64, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.build_graph().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng97TFpLRym2",
        "outputId": "de27919b-62ca-4a86-a14f-badb0d85cc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(64, 389)]          0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding_layer (Embed  (64, 389, 300)      8253600     ['input_1[0][0]']                \n",
            " ding)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_bi_lstm (Bidirectional  [(64, 389, 600),    1442400     ['encoder_embedding_layer[0][0]']\n",
            " )                               (64, 300),                                                       \n",
            "                                 (64, 300),                                                       \n",
            "                                 (64, 300),                                                       \n",
            "                                 (64, 300)]                                                       \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (64, 600)            0           ['encoder_bi_lstm[0][1]',        \n",
            "                                                                  'encoder_bi_lstm[0][3]']        \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (64, 600)            0           ['encoder_bi_lstm[0][2]',        \n",
            "                                                                  'encoder_bi_lstm[0][4]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,696,000\n",
            "Trainable params: 1,442,400\n",
            "Non-trainable params: 8,253,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.plot_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "aaJFf-ELdIZo",
        "outputId": "a3128210-bec0-4ea3-9c8e-a5748442be29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Decoder"
      ],
      "metadata": {
        "id": "dtM9nOQrf3jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Container classes\n",
        "# Reference :- https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "class DecoderInput(NamedTuple):\n",
        "  new_token: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "metadata": {
        "id": "73wq7CTiTQpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  # Reference:- https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    self.W1 = Dense(units, use_bias=False, name='Wb1_attention_weights')\n",
        "    self.W2 = Dense(units, use_bias=False, name='Wb2_attention_weights')\n",
        "\n",
        "    self.attention = AdditiveAttention(use_scale=True)\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    \"\"\"\n",
        "    This layer takes 3 inputs:\n",
        "      - the query; this will be generated by the decoder, later,\n",
        "      - the value: the output of the encoder,\n",
        "      - the mask: to exclude the padding, i.e., context_batch != 0.\n",
        "    \"\"\"\n",
        "    #W1@ht\n",
        "    w1_query = self.W1(query)\n",
        "    #W2@hs\n",
        "    w2_key = self.W2(value)\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask = [query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    \n",
        "    return context_vector, attention_weights\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               vocab_size, \n",
        "               embedding_matrix, \n",
        "               embedding_dimension,\n",
        "               units, \n",
        "               batch_size, \n",
        "               max_length_context,\n",
        "               max_length_question,\n",
        "               **kwargs):\n",
        "    \n",
        "    super(Decoder, self).__init__(**kwargs)\n",
        "    self.batch_size = tf.constant(batch_size)\n",
        "    self.max_length_question = max_length_question\n",
        "    self.max_length_context = tf.constant(max_length_context)\n",
        "    self.embedding_dimension = tf.constant(embedding_dimension)\n",
        "    self.units = tf.constant(units)\n",
        "\n",
        "    # Layers definition\n",
        "    self.inputs = Input(shape=(None,), batch_size=self.batch_size)\n",
        "                        \n",
        "    # Embedding for the questions\n",
        "    self.embedding = Embedding(input_dim=vocab_size+1,\n",
        "                               output_dim=embedding_dimension,\n",
        "                               input_length=self.max_length_question,\n",
        "                               embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                               trainable=False,  #?\n",
        "                               mask_zero=False,\n",
        "                               name='decoder_embedding_layer')\n",
        "    \n",
        "    # The LSTM layer\n",
        "    self.lstm_layer = LSTM(units,\n",
        "                          return_sequences=True,\n",
        "                          return_state=True,\n",
        "                          recurrent_initializer='glorot_uniform',\n",
        "                          use_bias=True,\n",
        "                          input_shape=(self.max_length_question, embedding_dimension),\n",
        "                          name='decoder_lstm_layer')\n",
        "\n",
        "    # The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(units)\n",
        "\n",
        "    # Parameters to be learned\n",
        "    self.Wt = Dense(units, activation=tf.math.tanh, use_bias=False, name='decoder_Wt_weights')\n",
        "\n",
        "    # For the word probabilities\n",
        "    # self.Ws = Dense(self.dec_units, activation=tf.nn.softmax, use_bias=False)\n",
        "    self.Ws = Dense(vocab_size, activation=tf.nn.softmax, use_bias=False, name='decoder_Ws_weights')\n",
        "\n",
        "  def call(self, \n",
        "            inputs: DecoderInput, \n",
        "            state=None) -> Tuple[DecoderOutput, Tuple[tf.Tensor]]:\n",
        "\n",
        "    # Lookup the embeddings for the questions\n",
        "    x = self.embedding(inputs.new_token)\n",
        "    # embedded_tensor shape: (batch_size, 1, embedding_dimension)\n",
        "    if tf.shape(x).shape == 2: x = tf.expand_dims(x, axis=1)\n",
        "\n",
        "    # Process one step with the RNN\n",
        "    # LSTM expects inputs of shape: (batch_size, timestep, feature)\n",
        "    cell_output, hidden_dec_state, cell_dec_state = self.lstm_layer(x, initial_state=state)\n",
        "\n",
        "    # Use the LSTM cell output as the query for the attention over the encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=cell_output, \n",
        "        value=inputs.enc_output, \n",
        "        mask=inputs.mask)\n",
        "\n",
        "    # Join the context_vector and cell outpyt [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    cell_output_and_context_vector = tf.concat([cell_output, context_vector], axis=-1)\n",
        "\n",
        "    # at = tanh(Wt@[ht, ct])\n",
        "    attention_vector = self.Wt(cell_output_and_context_vector)\n",
        "\n",
        "    # logits = softmax(Ws@at)\n",
        "    logits = self.Ws(attention_vector)\n",
        "\n",
        "    return DecoderOutput(logits, attention_weights), (hidden_dec_state, cell_dec_state)"
      ],
      "metadata": {
        "id": "V_-Lef2CqUW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Test the decoder stack\n",
        "\n",
        "The decoder will take as input:\n",
        "1. `new_tokens`: the last token generated of shape `(batch_size, 1)`, namely the token obrained in the previous time step of the decoder (we will initialize the decoder with the `\"<sos>\"` token);\n",
        "2. `enc_output`: this is the representation produced by the `Encoder` of shape `(batch_size, max_length_context, enc_units)`;\n",
        "3. `mask`: this is the mask, that is a boolean tensor, indicating which tokens will be considered in the decoding of shape `(batch_size, max_length_context)`; \n",
        "4. `decoder_state`: the previous state of the decoder, namely the internal state of the decoder's LSTM (the paper suggests to input the hidden and cell state produced by the Bi-LSTM). The shape is `[(batch_size, enc_units), (batch_size, enc_units)]`.\n",
        "\n"
      ],
      "metadata": {
        "id": "IF5J42g1l-be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_config['vocab_size'] = len(word_to_idx[1])\n",
        "decoder_config['max_length_question'] = dataset.train.element_spec[1].shape[1]\n",
        "decoder_config['max_length_context'] = dataset.train.element_spec[0].shape[1]\n",
        "\n",
        "decoder = Decoder(**decoder_config, embedding_matrix=embedding_matrix)"
      ],
      "metadata": {
        "id": "kS0UBnMzTbie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "start_tag_index = word_to_idx[2]['<sos>']\n",
        "first_token = tf.squeeze(tf.constant([[start_tag_index]] * decoder_config['batch_size']), axis=1)\n",
        "# first_token = tf.constant([[4]] * decoder_config['batch_size'])"
      ],
      "metadata": {
        "id": "KeMvqDnrTkf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result, decoder_state = decoder(\n",
        "    inputs = DecoderInput(first_token, \n",
        "                          encoder_outputs,\n",
        "                          mask=(example_context_batch != 0)),\n",
        "    state = encoder_state\n",
        ")\n",
        "\n",
        "hidden_dec_state, cell_dec_state = decoder_state\n",
        "\n",
        "print(f'Logits shape: (batch_size, t, output_vocab_size) {decoder_result.logits.shape}')\n",
        "print(f'Hidden state shape: (batch_size, dec_units) {hidden_dec_state.shape}')\n",
        "print(f'Cell state shape: (batch_size, dec_units) {cell_dec_state.shape}')"
      ],
      "metadata": {
        "id": "BF6PWsNYfmUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f677b858-a368-4de2-a26c-d5d98ba32ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (batch_size, t, output_vocab_size) (64, 1, 27511)\n",
            "Hidden state shape: (batch_size, dec_units) (64, 600)\n",
            "Cell state shape: (batch_size, dec_units) (64, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we cannot provide a detailed summary or a handy plot due to the fact that we pass to the decoder model a structured input which is not preferred by tensorflow."
      ],
      "metadata": {
        "id": "T9FZVz2QyLkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1AJWwcDacEj",
        "outputId": "37a33087-89e0-44ea-ea1c-c5787ebc6b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_embedding_layer (Em  multiple                 8253600   \n",
            " bedding)                                                        \n",
            "                                                                 \n",
            " decoder_lstm_layer (LSTM)   multiple                  2162400   \n",
            "                                                                 \n",
            " bahdanau_attention (Bahdana  multiple                 720600    \n",
            " uAttention)                                                     \n",
            "                                                                 \n",
            " decoder_Wt_weights (Dense)  multiple                  720000    \n",
            "                                                                 \n",
            " decoder_Ws_weights (Dense)  multiple                  16506600  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,363,200\n",
            "Trainable params: 20,109,600\n",
            "Non-trainable params: 8,253,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on. This means that the decoder will produce a vector of probabilities associated to each vocabulary word. That is, a vector of logits $l_b \\in \\mathbb{R}^{\\mathcal{V}}$ for each element $b$ in the batch, namely indicating the next probable token for a given sentence. Since they are logits they should sum up to `1.0`, evenutally a number really close to it. "
      ],
      "metadata": {
        "id": "BBIQDE0Sl6k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result.logits[0, 0, :].numpy().sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO-C7ELdlv1u",
        "outputId": "7a85eab3-b624-4a1b-dd5c-d91741298023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we sample a token according to the logits computed by the decoder."
      ],
      "metadata": {
        "id": "xrN_dTRtGdQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_tokens = tf.random.categorical(\n",
        "    logits=decoder_result.logits[:, 0, :],\n",
        "    num_samples=1, \n",
        "    seed=dataset_config['random_seed'])\n",
        "vocab = np.array(list(word_to_idx[1].keys()))\n",
        "\n",
        "first_word = list(vocab[tf.squeeze(sampled_tokens, axis=-1).numpy()])\n",
        "first_word[:5]"
      ],
      "metadata": {
        "id": "kGGwivobvx_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e42f40-238e-406f-9367-c37578549aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oskar', 'thalidomide', 'worker', 'donates', 'falles']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IO1MeOs9Q_-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_result, _ = decoder(\n",
        "    inputs = DecoderInput(sampled_tokens, \n",
        "                          encoder_outputs,\n",
        "                          mask=(example_context_batch != 0)),\n",
        "    state = decoder_state\n",
        ")\n",
        "\n",
        "sampled_tokens = tf.random.categorical(\n",
        "    logits=decoder_result.logits[:, 0, :], \n",
        " \n",
        "    num_samples=1, \n",
        "    seed=dataset_config['random_seed'])\n",
        "sampled_tokens = tf.squeeze(sampled_tokens, axis=-1).numpy()\n",
        "\n",
        "first_word = list(vocab[sampled_tokens])\n",
        "first_word[:5]"
      ],
      "metadata": {
        "id": "Y2ixRaJZn271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bc1382-9dd9-48bb-e6f2-4a2000ee15c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['brewed', 'reconfigure', 'sixth', 'succeeded', 'catalysts']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training for QG"
      ],
      "metadata": {
        "id": "qIoySQKuIGlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Loss\n",
        "\n",
        "The **QG** task is defined as finding $\\hat{y}$ such that:\n",
        "$$\n",
        "\\hat{y} = \\arg{\\max_y P(y|x)}  \n",
        "$$\n",
        "where $P(y|x)$ is the conditional log-likelihood of the predicted question sentence $y$ given the input $x$. Du et al. shown that the conditional probability could be factorized in:\n",
        "$$\n",
        "P(y|x) = \\prod_{t=1}^{|y|} P(y_t|x, y_{<t})\n",
        "$$\n",
        "where the probability of each $y_t$ is predicted based on all the words that have been generated upon time $t$, namely $y_{<t}$.\n",
        "\n",
        "This means that given a training corpus of sentence-question pairs $\\mathcal{S} = \\{(x^{(i)}, y^{(i)})\\}_{i=1}^N$, the objective is to minimize the negative log-likelihood:\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\mathcal{L} &= - \\sum_{i=1}^N \\log P(y^{(i)}|x^{(i)}; \\theta)\\\\\n",
        "            &=  - \\sum_{i=1}^N \\sum_{j=1}^{|y^{(i)}|} \\log P (y_j^{(i)}|x^{(i)}, y_{<j}^{(i)}; \\theta)\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "qyRA2RxZNsx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'conditional_ll_loss'\n",
        "\n",
        "    # The loss needs to work with logits since the decoder is outputting the most probable token\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True,\n",
        "        reduction='none'\n",
        "    )\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch\n",
        "    # Shape of y_true = (batch_size, max_length_question)\n",
        "    # Shape of y_pred = (batch_size, max_length_question, vocab_size)\n",
        "    loss = self.loss(y_true=y_true, y_pred=y_pred)\n",
        "    \n",
        "    # Mask of the losses on the padding\n",
        "    mask = tf.math.not_equal(y_true, 0)\n",
        "    loss = tf.boolean_mask(loss, mask)\n",
        "    loss = tf.reduce_sum(loss)\n",
        "\n",
        "    # Return the total\n",
        "    return loss"
      ],
      "metadata": {
        "id": "IP_UunM3MUtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 QG model and training step implementation\n",
        "\n",
        "The training step should:\n",
        "1. Run the encoder on the `input_tokens` to get the `encoder_outputs`, `hidden_state` and `cell_state`. "
      ],
      "metadata": {
        "id": "iwLiPsCyNuor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QGeneratorTrainer(tf.keras.Model):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_dimension,\n",
        "               embedding_matrix,\n",
        "               units,\n",
        "               batch_size,\n",
        "               max_length_context,\n",
        "               max_length_question,\n",
        "               use_tf_function=True):\n",
        "    \"\"\"\n",
        "    Prepare the model for the training. It builds the both the encoder and the decoder.\n",
        "    Also it defines a wrapper to use the tf.function compilation for the tensorflow computational\n",
        "    graph.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(\n",
        "        vocab_size,\n",
        "        embedding_matrix,\n",
        "        embedding_dimension,\n",
        "        units,\n",
        "        batch_size,\n",
        "        max_length_context)\n",
        "\n",
        "    self.decoder = Decoder(\n",
        "        vocab_size,\n",
        "        embedding_matrix,\n",
        "        embedding_dimension,\n",
        "        units, \n",
        "        batch_size,\n",
        "        max_length_context,\n",
        "        max_length_question,\n",
        "        )\n",
        "    \n",
        "    self.use_tf_function = use_tf_function\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    \"\"\"\n",
        "    Wrapper that switches on and off the tf.function compilation for performance, see the \n",
        "    tensorflow documentation for the computation graph.\n",
        "    \"\"\"\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)\n",
        "\n",
        "  @tf.function\n",
        "  def _tf_train_step(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "\n",
        "  def _train_step(self, inputs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # Extract context and target\n",
        "    context, question = inputs\n",
        "    max_question_length = question.shape[1]\n",
        "\n",
        "    # Generate teh mask for both the context and the question\n",
        "    context_mask = self.__get_mask(context)\n",
        "    question_mask = self.__get_mask(question)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Encode the input\n",
        "      encoder_output, encoder_state = self.encoder(context)\n",
        "\n",
        "      # The decoder should be initialized with the encoder last state \n",
        "      decoder_state = encoder_state\n",
        "      loss = tf.constant(0.0)\n",
        "      t = 0\n",
        "\n",
        "      # Reference :- https://www.tensorflow.org/guide/function\n",
        "      # We have to run the decoder for all the length of the question \n",
        "      while t < max_question_length - 1:\n",
        "        # We have to pass two tokens:\n",
        "        #   1. the token at time step t, namely the token in which we need to start run the decoder \n",
        "        #   2. the token at time step t+1, that is the next token in the sequence that needs to be compared with\n",
        "        new_token = tf.gather(question, t, axis=1)\n",
        "        target_token = tf.gather(question, t+1, axis=1)\n",
        "\n",
        "        step_loss, decoder_state = self.__run_decoder(\n",
        "            (new_token, target_token),\n",
        "            context_mask,\n",
        "            encoder_output,\n",
        "            decoder_state)\n",
        "        \n",
        "        loss = loss + step_loss\n",
        "        t = t + 1\n",
        "\n",
        "      # Average the loss for all the legit tokens\n",
        "      avg_loss = loss / tf.math.reduce_sum(tf.cast(question_mask, dtype=loss.dtype))\n",
        "\n",
        "    # Apply an optimization step\n",
        "    tr_variables = self.trainable_variables\n",
        "    grads = tape.gradient(avg_loss, tr_variables)\n",
        "    \n",
        "    # Apply some clipping, by norm as written in the paper\n",
        "    grads = [tf.clip_by_norm(g, 5.0) for g in grads]\n",
        "    self.optimizer.apply_gradients(zip(grads, tr_variables))\n",
        "\n",
        "    return {f'batch_loss': avg_loss}\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def __run_decoder(self, \n",
        "                    tokens, \n",
        "                    context_mask, \n",
        "                    encoder_output, \n",
        "                    decoder_state):\n",
        "    \"\"\"\n",
        "    Run a single iteration of the decoder and computers the incremental loss between the\n",
        "    produced token and the token in the target input.\n",
        "\n",
        "    \"\"\"\n",
        "    new_token, target_token = tokens\n",
        "    \n",
        "    # Run the decoder one time\n",
        "    decoder_result, decoder_state = self.decoder(\n",
        "        inputs = DecoderInput(\n",
        "            new_token=new_token,\n",
        "            enc_output=encoder_output,\n",
        "            mask=context_mask),\n",
        "        state = decoder_state)\n",
        "  \n",
        "    y_true = target_token\n",
        "    y_pred = decoder_result.logits\n",
        "\n",
        "    step_loss = self.loss(y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "    return step_loss, decoder_state\n",
        "\n",
        "  def __get_mask(self, tokens): return tf.math.not_equal(tokens, 0)"
      ],
      "metadata": {
        "id": "8xSn_StMq9cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_model = QGeneratorTrainer(**encoder_config, \n",
        "            max_length_question=decoder_config['max_length_question'],\n",
        "            embedding_matrix=embedding_matrix,\n",
        "            use_tf_function=True)\n",
        "\n",
        "trainer_config['loss'] = MaskedLoss()\n",
        "\n",
        "qg_model.compile(\n",
        "    optimizer=trainer_config['optimizer'],\n",
        "    loss=trainer_config['loss']\n",
        ")"
      ],
      "metadata": {
        "id": "zwKc0rvrIWkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 Simple Training\n",
        "The first call with `use_tf_function=True` will be slow since it has to trace the function. So be patient or try `use_tf_function=False` 😀"
      ],
      "metadata": {
        "id": "SPSDqU3_3nOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataset.train))\n",
        "qg_model.train_step(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf5JzL9T47Ha",
        "outputId": "b3cb09f7-80e4-4565-e924-0953f58c4739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method QGeneratorTrainer._train_step of <__main__.QGeneratorTrainer object at 0x7f5cc7535990>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method QGeneratorTrainer._train_step of <__main__.QGeneratorTrainer object at 0x7f5cc7535990>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=9.493801>}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses = []\n",
        "for n in tqdm(range(10)):\n",
        "  # print('.', end='')\n",
        "  logs = qg_model.train_step(next(iter(dataset.train)))\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)\n",
        "print()\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "E0ZatZ4g-5iq",
        "outputId": "0f77effc-fc84-4ad6-f8b8-37bbea6c6c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:10<00:00,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[9.483099, 9.500234, 9.476356, 9.4905405, 9.493801, 9.472937, 9.51583, 9.496226, 9.483933, 9.484765]\n",
            "CPU times: user 7.6 s, sys: 5 s, total: 12.6 s\n",
            "Wall time: 10.7 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Checkpoints\n",
        "\n",
        "See [Manual Checkpointing](https://www.tensorflow.org/guide/checkpoint)."
      ],
      "metadata": {
        "id": "x6uDOVpginU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"tf_ckpt\")"
      ],
      "metadata": {
        "id": "gEMKO8azio4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_iterator = iter(dataset.train) \n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "manager = tf.train.CheckpointManager(checkpoint,\n",
        "                                     checkpoint_prefix,\n",
        "                                     max_to_keep=3)"
      ],
      "metadata": {
        "id": "5tNJR_fRi7qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Train the model"
      ],
      "metadata": {
        "id": "fF8BfykX5faH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key) -> None:\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_ends(self, n, logs):\n",
        "    self.logs.append(logs[self.key])"
      ],
      "metadata": {
        "id": "uhSLln405mfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_loss = BatchLogs('batch_loss')\n",
        "history = qg_model.fit(dataset.train, epochs=trainer_config['epochs'], callbacks=[batch_loss], verbose='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys97OwVn61UT",
        "outputId": "49e920fe-7c25-45f9-f545-6245fd44e58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "112/112 [==============================] - 124s 1s/step - batch_loss: 9.4343\n",
            "Epoch 2/3\n",
            "112/112 [==============================] - 119s 1s/step - batch_loss: 9.3608\n",
            "Epoch 3/3\n",
            "112/112 [==============================] - 119s 1s/step - batch_loss: 9.3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Inference for QG\n",
        "In this section we will provide the class and the methods for the inference part. More specifically, both auxiliary and inferencing methods:\n",
        "1. `token_to_string()`:\n",
        "2. `string_to_token()`:\n",
        "3. `create_mask()`:\n",
        "4. `temperature_sampling()`:\n",
        "5. `generate_question()`:"
      ],
      "metadata": {
        "id": "ezgR7c68_0nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QGeneratorInference(tf.Module):\n",
        "  def __init__(self, encoder, decoder, tokenizer, word_to_idx, use_tf_function):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.tokenizer = tokenizer\n",
        "    self.word_to_idx = word_to_idx\n",
        "   \n",
        "    self.result_tokens = None\n",
        "    self.result_text = None\n",
        "    self.token_mask = self.create_mask()\n",
        "\n",
        "    self.start_idx = word_to_idx['<sos>']\n",
        "    self.end_idx = word_to_idx['<eos>']\n",
        "    self.use_tf_function = False\n",
        "\n",
        "  def token_to_string(self, result_tokens: tf.Tensor):  \n",
        "    \"\"\"\n",
        "    This method converts token IDs to text by using a given mapping.\n",
        "    \"\"\"\n",
        "    list_tokens = result_tokens.numpy().tolist()\n",
        "    list_text = self.tokenizer.sequences_to_texts(list_tokens)\n",
        "    list_text = tf.convert_to_tensor([list_text])\n",
        "    result_text = tf.strings.reduce_join(list_text, axis=0, separator=' ')\n",
        "    result_text = tf.strings.strip(result_text)\n",
        "    \n",
        "    self.result_tokens = result_tokens\n",
        "    self.result_text = result_text\n",
        "    return result_text\n",
        "\n",
        "  def string_to_token(self, result_str: tf.Tensor):\n",
        "    \"\"\"\n",
        "    This method converts texts to token IDs by using a given mapping.\n",
        "    \"\"\"  \n",
        "    list_str = [s.decode(\"utf-8\") for s in result_str.numpy().tolist()]\n",
        "    list_tokens = self.tokenizer.texts_to_sequences(list_str)\n",
        "    list_tokens = tf.convert_to_tensor(list_tokens, dtype=tf.int64)\n",
        "    result_tokens = tf.squeeze(tf.split(list_tokens, num_or_size_splits=list_tokens.shape[0], axis=0), axis=1)\n",
        "\n",
        "    return result_tokens\n",
        "  \n",
        "  def create_mask(self):\n",
        "    \"\"\"\n",
        "    This method creates a mask for the padding, the unknwon words and the start/ending tokens.\n",
        "    \"\"\"\n",
        "    masked_words = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
        "    token_mask_ids = [self.tokenizer.word_index[mask] for mask in masked_words]\n",
        "\n",
        "    token_mask = np.zeros(shape=(len(self.word_to_idx),), dtype=bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    return token_mask\n",
        "\n",
        "  def temperature_sampling(self, logits, temperature=0.5):\n",
        "    \"\"\"\n",
        "\n",
        "    For the temperature choice see here:\n",
        "      Reference :- https://nlp.stanford.edu/blog/maximum-likelihood-decoding-with-rnns-the-good-the-bad-and-the-ugly/\n",
        "    \"\"\"\n",
        "    # First of all we use broadcast the generated mask to the expected logits' shape\n",
        "    # token_mask shape: (batch_size, timestep, vocab_size)\n",
        "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    # The logits for all the tokens that have to not be used are set top -1.0\n",
        "    logits = tf.where(token_mask, -1.0, logits)\n",
        "\n",
        "    # Freezing function\n",
        "    # Higher temperature -> greater variety\n",
        "    # Lower temperature -> grammatically correct\n",
        "    if temperature == 0.0:\n",
        "      # the freezing function is the argmax\n",
        "      new_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "      # the freezing function now scales the logits.\n",
        "      # for temperature == 1.0 is the identity function\n",
        "      logits = tf.squeeze(logits, axis=1)\n",
        "      new_token = tf.random.categorical(logits/temperature, num_samples=1)\n",
        "    return new_token\n",
        "\n",
        "  def predict(self, inputs, max_length, return_attention):\n",
        "    \"\"\"\n",
        "    Wrapper that switches on and off the tf.function compilation for performance, see the \n",
        "    tensorflow documentation for the computation graph.\n",
        "    \"\"\"\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_generate_question(inputs, max_length, return_attention)\n",
        "    else:\n",
        "      return self._generate_question(inputs, max_length, return_attention)\n",
        "\n",
        "  @tf.function\n",
        "  def _tf_generate_question(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "\n",
        "  def _generate_question(self, \n",
        "                        inputs,\n",
        "                        max_length,\n",
        "                        return_attention=True,\n",
        "                        temperature=0.5):\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "    # Similarly for what it has been done in the train step\n",
        "    encoder_output, encoder_state = self.encoder(inputs)\n",
        "    decoder_state = encoder_state\n",
        "\n",
        "    # Generate the first token of each sentence, that is the <sos> token\n",
        "    new_token = tf.fill([batch_size, 1], self.start_idx)\n",
        "\n",
        "    result_tokens = []\n",
        "    attention = []\n",
        "    timestep = 0\n",
        "    while timestep < max_length:\n",
        "      timestep = timestep + 1\n",
        "      \n",
        "      # Decode the token at the next timestep\n",
        "      decoder_result, decoder_state = self.decoder(\n",
        "        inputs = DecoderInput(\n",
        "            new_token=new_token,\n",
        "            enc_output=encoder_output,\n",
        "            mask=(inputs != 0)),\n",
        "        state = decoder_state)\n",
        "      \n",
        "      attention.append(decoder_result.attention_weights)\n",
        "\n",
        "      # Sample the new token accordingly to the distribution produced by the decoder\n",
        "      new_token = self.temperature_sampling(decoder_result.logits, temperature)\n",
        "\n",
        "      # if a sequence has reached <eos> set it as done\n",
        "      \n",
        "      result_tokens.append(new_token)\n",
        "    \n",
        "    #\n",
        "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "    result_text = self.token_to_string(result_tokens)\n",
        "\n",
        "    attention_stack = tf.concat(attention, axis=-1)\n",
        "\n",
        "    if return_attention:\n",
        "      attention_stack = tf.concat(attention, axis=1)\n",
        "      return {'text': result_text, 'attention': attention_stack}\n",
        "    else:\n",
        "      return {'text': result_text}"
      ],
      "metadata": {
        "id": "gn2NTxAq_2sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_generator = QGeneratorInference(qg_model.encoder, \n",
        "                                   qg_model.decoder, \n",
        "                                   dataset_creator.tokenizer, \n",
        "                                   word_to_idx[1], \n",
        "                                   use_tf_function=True)"
      ],
      "metadata": {
        "id": "1Q2pWJ5YDfqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_logits = tf.random.normal([5, 1, len(word_to_idx[1])])\n",
        "example_output_tokens = qg_generator.temperature_sampling(example_logits, temperature=1.0)"
      ],
      "metadata": {
        "id": "fklYEd1e6XOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qg_generator.predict(example_output_tokens, max_length=10, return_attention=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RO-7QCL_MSc",
        "outputId": "5bd1b528-b49a-438a-8c5f-dbc698dfb424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              " array([b'prelates gauthia steep hirsch unfurl neurology corsica matte gharm bayan',\n",
              "        b'narcokleptocracy mevastatin georgia hannover 1925 566 basic deboned fortuna jhanas',\n",
              "        b'nrel healthy circuit frequency troublesome aufkl malamute unleashed civics employment',\n",
              "        b'stylized stratum ascription witnessed bre subsided juan vasubandhu substituted baltasar',\n",
              "        b'prefer kilby nanjing folklife disappearing 448 teau axis pseudogenes root'],\n",
              "       dtype=object)>}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bro = [[list(), 0.0]]\n",
        "print(bro)"
      ],
      "metadata": {
        "id": "Ha1sP-HiWgeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379b2101-d29f-40be-ff6f-557804d7c1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[], 0.0]]\n"
          ]
        }
      ]
    }
  ]
}